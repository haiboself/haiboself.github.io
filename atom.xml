<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-11-25T07:31:23.221Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>深入剖析kubernetes 1-4章阅读总结</title>
    <link href="http://example.com/2022/10/30/yuque/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90kubernetes1-4%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2022/10/30/yuque/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90kubernetes1-4%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</id>
    <published>2022-10-30T06:41:51.000Z</published>
    <updated>2022-11-25T07:31:23.221Z</updated>
    
    <content type="html"><![CDATA[<h1><span id="容器的来龙去脉">容器的来龙去脉</span></h1><h2><span id="paas">PaaS</span></h2><p>Paas 解决的是应用程序的<strong>托管</strong>、<strong>打包</strong>与<strong>分发</strong>问题，强调零停机时间部署、自动规模伸缩与负载均衡等功能。用户可以在云服务商租一批虚拟机，然后可以用脚本或手动的方式在上面部署应用。<br><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/FuPjLKiFVYa-DwRncFIWBNWGuK5j.png"><br>以 Cloud Foundry 这个 PaaS 项目为例，它的<strong>核心组件就是一套应用的打包和分发机制。</strong></p><ul><li>用户把应用、启动脚本等打包到一个压缩包中，上传后 Cloud Foundry 会通过调度器选择一个合适的虚拟机，然后通知这个机器的 Agent 下载应用压缩包并启动</li><li>由于需要在一个虚拟机上启动多个应用，Cloud Foundry 会调用操作系统的 Cgroups 和 Namespace 机制为每个应用单独创建一个隔离环境唤做<strong>“沙盒”</strong>，然后在里面启动应用进程。</li></ul><p><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/FqlusSGRmjftiBMkQ_w3xUtbYSZ5.png"><br>这样就把多个应用在虚拟机中互不干扰的自动运行了起来，<strong>这些“隔离环境”，就是“容器”，</strong>后文具体介绍。</p><h2><span id="docker">Docker</span></h2><p>Docker 容器和 Cloud Foundry “沙箱”没有本质区别，它主要解决了 PaaS 中“应用打包难”的问题。<br>Docker 之前应用打包难：</p><ul><li>用户必须为每种语言、每种框架，甚至每个版本为一个一个打好的包。</li><li>打包过程没有章法可循，且在本地良好运行的应用，需要做很多配置和修改才能在 Paas 中运行。</li></ul><p>Docker 的解决方案:</p><ul><li>镜像，就是打包了应用程序 + 需要的<strong>整个操作系统</strong>，从而保证了本地环境和云端环境的<strong>高度一致</strong>，<strong>避免</strong>了用户通过“试错”来匹配不同运行环境之间差异的过程。</li></ul><p>Docker 只是解决了打包部分的问题，但是<strong>并不负责“分发”、“应用部署”。</strong><br>因此，Docker 提供了 Swarm 工具来做集群管理，swarm 集群由管理节点（manager）和工作节点（work node）构成。</p><ul><li><strong>swarm mananger</strong>：负责整个集群的管理工作包括集群配置、服务管理等所有跟集群有关的工作。</li><li><strong>work node</strong>：即图中的 available node，主要负责运行相应的服务来执行任务（task）。</li></ul><p><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/Fml0oIoNRcC085M7LJ_vSbfUalz-.png"></p><p>Compose（Fig）项目来做容器编排。</p><ul><li>容器编排：指用户通过某些工具或配置来完成一组虚拟机以及关联资源的定义、配置、创建、删除等工作。</li><li>对 docker 而言，编排就是对 docker <strong>容器的一系列定义、配置和创建动作的管理</strong>。比如定义多个容器之间的<strong>依赖关系</strong>[2]</li></ul><p><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/FndkxBS64up84mNDriLbusNE5F1-.png"></p><h2><span id="k8s">K8s</span></h2><p>“容器的价值非常有限，真正有价值的是<strong>容器编排</strong>”，很多项目（Yarn，Mesos，Docker Swarm）擅长的是把一个容器按照某种规则放置到某个最佳节点上执行，这种功能成为“调度”。K8s 擅长的是<strong>编排</strong>，即按照用户的意愿和整个系统的规则，<strong>完全自动化地处理好容器之间的各种关系。</strong><br><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/FqqGf1h_NkB7e4uMpFL4ZXifYGaC.png"><br>[14]</p><h1><span id="容器技术基础">容器技术基础</span></h1><p>容器技术的核心功能，就是通过约束和修改进程的“动态表现”，为其创造一个“边界”。以 Linux 容器为例</p><ol><li>NameSpace 技术是用来进行<strong>隔离</strong>资源的主要方法。</li><li>Cgroups 技术是用来<strong>限制</strong>（限制 cpu、内存、存储等资源）的主要手段</li></ol><h2><span id="namespace3">Namespace[3]</span></h2><p>Linux Namespace 提供了一种内核级别隔离系统资源的方法，通过将系统的全局资源放在不同的 Namespace 中，来实现资源隔离的目的。 目前提供了 6 种系统资源的隔离机制</p><ul><li>Mount：隔离文件系统</li><li>UTS：隔离主机名和域名信息</li><li>IOC：隔离进程间通信</li><li>PID：隔离进程的 ID</li><li>Network：隔离网络资源</li><li>User：隔离用户和用户组的 ID</li></ul><p>以 PID 隔离[7]为例，举个例子：<br>1）在宿主机启动一个 docker 容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it busybox /bin/sh</span><br></pre></td></tr></table></figure><p>2）查看进程号<br>左边是容器(隔离出的空间)的中的进程号为 1，对应到右边宿主机中真实的进程好为 30789<br><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/Fr0JDa5yTx_7CWJCw6P8QCuJv42x.png"><br>3）实际上，docker 利用 Namespace 机制，施了一个障眼法，对被隔离的进程空间动了手脚，使得这些进程看到的是“重新计算过的 PID”<br><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/FqIBHO5lcO-mwGGk6xle1tgFLQ7W.png"></p><p>实际上，在创建进程时候传递对应的 NameSpace 参数，来对进程上下文施展各种障眼法，这样进程就只能看到所属 NameSpace 下的资源信息。容器就使用了这种技术，Docker 启动的还是原来的应用进程，只不过在创建这些进程时，Docker 为他们加上了各种各样的 Namespace 参数。所以：<strong>容器其实只是一种特殊的进程，用户应用实际上就是容器中 PID&#x3D;1 的进程。</strong><br><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/FmpK9vucAm0UthqFNZ-9di1QrAWN.png"></p><h2><span id="cgroups">Cgroups</span></h2><p>Linux Cggroups(Linux control groups) 最主要的作用就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。cgroup 通过以下组件来抽象进程和资源[9]</p><ul><li>task：任务，对应进程</li><li>subsystem：子系统，具体的资源控制器，控制某个特定的资源使用，如 cpu 子系统控制 cpu 使用时间</li><li>cgroup：控制组，一组任务和子系统的关联关系，标识对这些任务进行怎样的资源控制策略</li><li>hierarchy：层级树，一些列 cgroup 组成的树形结构。</li></ul><p>进程和 cgroup 是多对多的关系[10]：<br><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/FmRJsf10zALtbAr2spjzOWB8tPN8.png"></p><p>Cgroup 使用示例：<br>1）Linux 下 cgroups 以文件和目录方式组织在 &#x2F;sys&#x2F;fs&#x2F;cgroup 下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-16-5-centos ~]<span class="comment"># mount -t cgroup</span></span><br><span class="line">cgroup on /sys/fs/cgroup/systemd <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)</span><br><span class="line">cgroup on /sys/fs/cgroup/perf_event <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)</span><br><span class="line">cgroup on /sys/fs/cgroup/blkio <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,blkio)</span><br><span class="line">cgroup on /sys/fs/cgroup/net_cls,net_prio <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio)</span><br><span class="line">cgroup on /sys/fs/cgroup/devices <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,devices)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpuset <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)</span><br><span class="line">cgroup on /sys/fs/cgroup/memory <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,memory)</span><br><span class="line">cgroup on /sys/fs/cgroup/freezer <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,freezer)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpu,cpuacct <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)</span><br><span class="line">cgroup on /sys/fs/cgroup/pids <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,pids)</span><br><span class="line">cgroup on /sys/fs/cgroup/hugetlb <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)</span><br><span class="line">cgroup on /sys/fs/cgroup/rdma <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,rdma)</span><br></pre></td></tr></table></figure><p>2）以 cpu 使用限制为例，在 cpu 下创建 container 目录（控制组）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-16-5-centos container]<span class="comment"># ls</span></span><br><span class="line">cgroup.clone_children  cpuacct.stat   cpuacct.usage_all     cpuacct.usage_percpu_sys   cpuacct.usage_sys   cpu.cfs_period_us  cpu.shares  notify_on_release</span><br><span class="line">cgroup.procs           cpuacct.usage  cpuacct.usage_percpu  cpuacct.usage_percpu_user  cpuacct.usage_user  cpu.cfs_quota_us   cpu.stat    tasks</span><br></pre></td></tr></table></figure><p>3）限制 cpu 的使用，表示在 100ms 的时间内，被该控制组限制的进程只能使用 20ms 的 cpu 时间，可以将需要限制的进程 id 写入到 tasks 文件中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> 100000 &gt; /sys/fs/cgroup/cpu/container/cpu.cfs_period_us</span><br><span class="line"><span class="built_in">echo</span> 20000 &gt; /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us</span><br><span class="line"><span class="built_in">echo</span> $(pid) &gt; /sys/fs/cgroup/cpu/container/tasks</span><br></pre></td></tr></table></figure><p>Docker 创建 linux 容器时，只需要在每个子系统下创建对应的控制组（新建目录），然后在启动容器进程后，把整个进程的 PID 天蝎到对应控制组的 tasks 文件中就可以完成资源的限制。如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-16-5-centos container]docker run -it --cpu-period=100000 --cpu-quota=20000 busybox /bin/sh</span><br><span class="line">[root@VM-16-5-centos docker-4cd72e800ed85e9502818dfc1bec238f653da27e10ce61f74d50fb501f819200.scope]<span class="comment"># ls</span></span><br><span class="line">cgroup.clone_children  cpuacct.usage_all          cpuacct.usage_sys   cpu.shares</span><br><span class="line">cgroup.procs           cpuacct.usage_percpu       cpuacct.usage_user  cpu.stat</span><br><span class="line">cpuacct.stat           cpuacct.usage_percpu_sys   cpu.cfs_period_us   notify_on_release</span><br><span class="line">cpuacct.usage          cpuacct.usage_percpu_user  cpu.cfs_quota_us    tasks</span><br><span class="line">[root@VM-16-5-centos docker-4cd72e800ed85e9502818dfc1bec238f653da27e10ce61f74d50fb501f819200.scope]<span class="comment"># cat cpu.cfs_quota_us</span></span><br><span class="line">20000</span><br><span class="line">[root@VM-16-5-centos docker-4cd72e800ed85e9502818dfc1bec238f653da27e10ce61f74d50fb501f819200.scope]<span class="comment"># cat cpu.cfs_period_us</span></span><br><span class="line">100000</span><br><span class="line">[root@VM-16-5-centos docker-4cd72e800ed85e9502818dfc1bec238f653da27e10ce61f74d50fb501f819200.scope]<span class="comment">#</span></span><br></pre></td></tr></table></figure><h2><span id="rootfs13">Rootfs[13]</span></h2><p>容器进程应该“看到”，一个完全隔离、独立的文件环境，而不是继承自宿主机的文件系统。在 Linux 中要实现这一点，要借助 chroot(change root file system) 命令，可以将指定目录挂载为指定容器进程的根目录。<br><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/FnIJGJLeGcQ2TEom2KlEMqtXKcR9.png"><br>一般会在容器的根目录下“挂在一个完整的操作系统的文件系统目录”，这个用来为容器进程提供隔离后执行环境的文件系统，就是“容器镜像”，即 rootrs（根文件系统）；</p><ul><li>这些文件不包含操作系统内核，所以区别于虚拟机同一台机器上所有容器都是共享操作系统内核的。</li></ul><p>（容器和虚拟机的对比）<br><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/FquXMCuGlH5_c1UxS7y3yYNRFBtE.png"></p><ul><li>打包操作系统文件目录，赋予了容器的一致性：无论在本地、云端或其他机器上，只需解压打包好的镜像，这个应用运行所需要的完整的执行环境就能重现。</li></ul><h2><span id="总结">总结</span></h2><p>容器实际是由 Linux Namespace，Linux Cgroup 和 Rootfs 3 种技术构建出来的进程的隔离环境，一个运行的 Linux 容器，可以被一分为二的看待：</p><ol><li>容器镜像：一组联合挂载在 &#x2F;var&#x2F;lib&#x2F;docker&#x2F;aufs&#x2F;mnt 上的 rootfs，是容器的静态视图</li><li>容器运行时：一个由 Namespace + Cgroups 构成的隔离环境，是容器的动态视图</li></ol><h1><span id="k8s-的设计">K8s 的设计</span></h1><h2><span id="核心能力与定位">核心能力与定位</span></h2><p>在大规模集群中的各种任务之间运行，实际存在各种各样的关系。<strong>这些关系的处理才是作业编排和管理系统最困难的地方。K8s 的核心能力就是要解决这个问题，而不是拉取和部署镜像。</strong><br>K8s 的主要设计思路是：</p><ul><li>以统一的方式抽象底层基础设施能力（计算、存储、网络等）；定义任务编排的各种关系（如亲密关系、访问关系、代理关系）</li><li>以声明式 api（yaml）的方式对外暴露，从而允许用户基于这些抽象构建自己的上层 平台（如自己的 paas）</li><li>所以，K8s 的本质是 “平台的平台”，一个帮助用户构建上层平台的基础平台。</li></ul><p>如图，K8s 是如何定义任务编排的各种关系的</p><ul><li>Pod 中的容器共享同一个 Network Namespace、同组 Volume，从而实现高效交换信息。</li></ul><p><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/FqT-l2WFN3E5cXPtT6BLWL5eaxtH.png"></p><h2><span id="架构设计11">架构设计[11]</span></h2><p>分为 Master 控制节点和 Node 计算节点</p><ul><li>Master：Controller Manager 负责容器编排；整个集群的数据，由 Api Server 处理后存储在 etcd 中</li><li>Node：<ul><li>kubelet 主要负责和容器运行时（如 Docker）交互，交互依赖 CRI(container runtime interface)远程调用接口。如 Docker 通过 OCI 容器运行时规范同 Linux 交互，把 CRI 请求翻译为对 Linux 系统的调用（操作 Namespace，Cgroups 等）</li><li>Device Plugin：是 k8s 用来管理 GPU 等宿主机无力设备的主要组件，kubelet 通过 grpc 和其交互</li><li>CNI(container networking interface)：kubelet 调用其为容器配置网络</li><li>CSI(container storage interface)：kubelet 调用其为容器配置持久化存储</li></ul></li></ul><p><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/Ftx9_KrvSZ903pTOCaCN3mQaiDpF.png"></p><h2><span id="pod12">Pod[12]</span></h2><p>容器是一个单进程模型，容器不具备进程管理能力，所以一个容器中只包含一个应用进程是合理的；当几个应用（容器）之间具有协作关系，需要共享某些资源，必须放在一起去管理（如必须运行在同一台机器上）要怎么办，而 pod 就是 k8s 给出的解决方案。<br><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/Fk3BkRiAtTFhsYqOjba4-iBcv9f-.png"></p><p>Pod 实际上是个逻辑概念，无力上对应的是一组容器；除此之外，Pod 是 Kubernetes 分配资源的一个单位，因为里面的容器要共享某些资源，所以 Pod 也是 Kubernetes 的原子调度单位。</p><h1><span id="总结">总结</span></h1><p>PaaS 解决应用：打包、分发部署、托管执行方面的问题</p><ul><li>打包：缺乏标准，打包难问题 -&gt; docker 容器镜像（增量 rootfs、layer）解决了这个问题，成为事实上的打包标准；</li><li>执行：依赖 linux os 自身的 namespace、cgroups、chroot 实现的容器技术解决这方面的问题；<ul><li>namespace：隔离进程资源视图</li><li>cgroups：限制进程的资源使用</li></ul></li></ul><p>PaaS 的 3 个问题解决好后，K8s 解决更上层的问题：容器、应用编排。从而成为平台的平台；如 cloud foundry 和 k8s 的结合[15]：<br><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/FvLPmqKa4O6wE8DCJEgAS7Rin2xh.png"><br><img src="https://blog-1314398479.cos.ap-nanjing.myqcloud.com/undefined/Fr6IFeckIz1Ca5wmq17hLeSDqEUU.png"></p><h1><span id="引用">引用</span></h1><ol><li><a href="https://www.spiceworks.com/tech/cloud/articles/what-is-platform-as-a-service/">https://www.spiceworks.com/tech/cloud/articles/what-is-platform-as-a-service/</a></li><li><a href="https://medium.com/@krishnakummar/creating-block-diagrams-from-your-docker-compose-yml-da9d5a2450b4">https:&#x2F;&#x2F;medium.com&#x2F;@krishnakummar&#x2F;creating-block-diagrams-from-your-docker-compose-yml-da9d5a2450b4</a></li><li><a href="https://techtutorialsite.com/docker-vs-virtual-machines/">https://techtutorialsite.com/docker-vs-virtual-machines/</a></li><li><a href="https://www.slideshare.net/AdamFitzGerald/cf-overview-gitpro">https://www.slideshare.net/AdamFitzGerald/cf-overview-gitpro</a></li><li><a href="https://www.slideshare.net/jaxLondonConference/run-your-java-apps-on-cloud-foundry-andy-piper-pivotal">https://www.slideshare.net/jaxLondonConference/run-your-java-apps-on-cloud-foundry-andy-piper-pivotal</a></li><li><a href="https://blogs.sap.com/2018/06/05/cloud-native-with-containers-and-kubernetes-part-2/">https://blogs.sap.com/2018/06/05/cloud-native-with-containers-and-kubernetes-part-2/</a></li><li><a href="https://zhuanlan.zhihu.com/p/73248894">https://zhuanlan.zhihu.com/p/73248894</a></li><li><a href="https://www.nginx.com/blog/what-are-namespaces-cgroups-how-do-they-work/">https://www.nginx.com/blog/what-are-namespaces-cgroups-how-do-they-work/</a></li><li><a href="https://juejin.cn/post/6921299245685276686">https://juejin.cn/post/6921299245685276686</a></li><li><a href="https://tech.meituan.com/2015/03/31/cgroups.html">https://tech.meituan.com/2015/03/31/cgroups.html</a></li><li><a href="https://www.cnblogs.com/luoahong/p/12330735.html">https://www.cnblogs.com/luoahong/p/12330735.html</a></li><li><a href="http://dockone.io/article/9290">http://dockone.io/article/9290</a></li><li><a href="https://www.feiyiblog.com/2020/03/27/%E9%95%9C%E5%83%8F%E5%88%86%E5%B1%82%E7%BB%93%E6%9E%84%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A31/">https://www.feiyiblog.com/2020/03/27/%E9%95%9C%E5%83%8F%E5%88%86%E5%B1%82%E7%BB%93%E6%9E%84%E7%90%86%E8%AE%BA%E8%AF%A6%E8%A7%A31/</a></li><li><a href="https://blogs.sap.com/2018/10/19/cloud-foundry-and-kubernetes-where-do-they-differ-how-do-they-fit-together/">https://blogs.sap.com/2018/10/19/cloud-foundry-and-kubernetes-where-do-they-differ-how-do-they-fit-together/</a></li><li><a href="https://blogs.sap.com/2021/01/15/back-to-the-future-cloud-foundry-on-kubernetes/">https://blogs.sap.com/2021/01/15/back-to-the-future-cloud-foundry-on-kubernetes/</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;&lt;span id=&quot;容器的来龙去脉&quot;&gt;容器的来龙去脉&lt;/span&gt;&lt;/h1&gt;&lt;h2&gt;&lt;span id=&quot;paas&quot;&gt;PaaS&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;Paas 解决的是应用程序的&lt;strong&gt;托管&lt;/strong&gt;、&lt;strong&gt;打包&lt;/strong&gt;与&lt;stro</summary>
      
    
    
    
    <category term="云原生" scheme="http://example.com/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
    <category term="容器" scheme="http://example.com/tags/%E5%AE%B9%E5%99%A8/"/>
    
    <category term="docker" scheme="http://example.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Part 2: CHAPTER 9 Consistency and Consensus</title>
    <link href="http://example.com/2019/12/12/Part-2-CHAPTER-9-Consistency-and-Consensus/"/>
    <id>http://example.com/2019/12/12/Part-2-CHAPTER-9-Consistency-and-Consensus/</id>
    <published>2019-12-12T06:35:04.000Z</published>
    <updated>2022-11-25T07:03:39.058Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#">?</a></li><li><a href="#summary">Summary</a><ul><li><a href="#consistent">Consistent</a></li><li><a href="#consensus">Consensus</a></li></ul></li><li><a href="#consistency-guaranteess">Consistency Guaranteess</a></li><li><a href="#linearizability">Linearizability:</a><ul><li><a href="#implementing-linearizable-system">Implementing Linearizable System</a></li><li><a href="#the-cost-of-linearizability">The Cost of Linearizability</a></li></ul></li><li><a href="#ordering-guarantees">Ordering Guarantees</a><ul><li><a href="#ordering-and-causality">Ordering and Causality</a></li><li><a href="#sequence-number-ordering">Sequence Number Ordering</a></li><li><a href="#total-order-broadcast">Total Order Broadcast</a></li></ul></li><li><a href="#distributed-transactions-and-consensus">Distributed Transactions and Consensus</a><ul><li><a href="#atomic-commit-and-two-phase-commit2pc">Atomic Commit and Two-Phase Commit(2PC)</a><ul><li><a href="#from-single-node-to-distributed-atomic-commit">From single-node to distributed atomic commit</a></li><li><a href="#introduction-to-two-phase-cmmithttpswwww3cschoolcnarchitectroadarchitectroad-two-phase-commithtml">Introduction to two-phase cmmit</a></li><li><a href="#coordinator-failure">Coordinator failure</a></li></ul></li><li><a href="#distributed-transactions-in-practice">Distributed Transactions in Practice</a><ul><li><a href="#exactly-once-message-processing">Exactly-once message processing</a></li><li><a href="#xa-transaction">XA transaction</a></li><li><a href="#holding-locks-while-in-doubt">Holding locks while in doubt</a></li><li><a href="#recovering-from-coordinator-failure">Recovering from coordinator failure</a></li><li><a href="#limitations-of-distributed-transactions">Limitations of distributed transactions</a></li></ul></li><li><a href="#fault-tolerant-consensus">Fault-Tolerant Consensus</a><ul><li><a href="#consensus-algorithm-and-total-order-broadcast">Consensus algorithm and total order broadcast</a></li><li><a href="#limitations-of-consensus">Limitations of consensus</a></li></ul></li><li><a href="#membership-and-coordination-services">Membership and Coordination Services</a></li></ul></li></ul><!-- tocstop --><h2><span id>?</span></h2><ul><li>It turns out that there are deep connections between ordering, linearizability, and consensus. 阐明它们之间的关系?</li><li>相比于单机事务,分布式事务有何不同?如何实现?</li><li>了解 google spanner(事务) 和 zk(consensus) 的实现</li><li>CAP 定理的理解</li></ul><h2><span id="summary">Summary</span></h2><blockquote><p><a href="http://www.bailis.org/blog/linearizability-versus-serializability">http://www.bailis.org/blog/linearizability-versus-serializability</a></p></blockquote><h4><span id="consistent">Consistent</span></h4><p><strong>Linearizability</strong>: 提供 <code>stronger consistency</code>, make replicated data appear as though there were <code>only a single copy</code>, and to make all operations act on it <code>atomically</code></p><ul><li>优点: 易于理解</li><li>缺点: 对网络问题敏感,性能慢</li></ul><p><strong>Causality</strong>: which puts all operations in a single, totally <code>ordered </code>timeline, causality provides us with a <code>weaker consistency</code> model</p><ul><li>优点: 对网络问题不敏感</li><li>使用场景受限</li></ul><h4><span id="consensus">Consensus</span></h4><blockquote><p>Consensus algorithms are a huge breakthrough for distributed systems: they bring concrete <code>safety properties</code> (agreement, integrity, and validity) to systems where everything else is uncertain, and they nevertheless remain <code>fault-tolerant</code> (able to make progress as long as a majority of nodes are working and reachable). They provide <code>total order broadcast</code>, and therefore they can also implement linearizable atomic operations in a fault-tolerant way.</p></blockquote><p>定义: Deciding something in such a way that all nodes agree on what was decided, and such that the decision is irrevocable.</p><p>使用场景:</p><ul><li>Linearizable compare-and-set registers</li><li>Atomic transaction commit</li><li>Total order broadcast</li><li>Locks and leases</li><li>Membership&#x2F;coordination service</li><li>Uniqueness constraint</li></ul><p>Zookeeper:</p><ul><li>providing an “outsourced” consensus</li><li>failure detection</li><li>membership service</li></ul><h2><span id="consistency-guaranteess">Consistency Guaranteess</span></h2><p>分布式 db 中,由于网络等因素,数据不一致一定会发生,因此 Most replicated databases provide at least <code>eventual consistency</code>。</p><p><strong>eventual consistency:</strong> 所有 replicas 的数据最终会达到一致。</p><ol><li>this is a very weak guarantee—it doesn’t say anything about <code>when</code> the replicas will converge</li><li>难以使用和测试: you need to be constantly aware of its limitations and not accidentally assume too much</li></ol><p><strong>stronger consistency:</strong> 所有 replicas 数据总是保持一致</p><ul><li>缺点: worse performance, less fault-tolerant </li><li>优势: easier to use correctly</li></ul><blockquote><p>distributed consistency is mostly about <code>coordinating</code> the state of replicas in the face of delays and faults.</p></blockquote><h2><span id="linearizability">Linearizability:</span></h2><p><strong>3 个特质:</strong></p><ul><li>Recency gurantee</li><li>single operations on singel object</li><li>time dependency and always move forward in time</li></ul><p><strong>定义:</strong></p><p>Linearizability(atomic consistency) is a guarantee about <code>single operations</code> on <code>single objects.</code> It provides a <code>real-time</code> (i.e., wall-clock) guarantee on the behavior of a set of single operations (often reads and writes) on a single object。</p><p>Linearizability is a <code>recency guarantee</code>(once a new value has been written or read, all subsequent reads see the value that was written, until it is overwritten again) on reads and writes of a register (an individual object). It <code>doesn’t group operations</code> together into transactions.</p><p><strong>Vs Serializability:</strong></p><p>linearizability can be viewed as a special case of strict serializability where transactions are restricted to consist of a single operation applied to a single object.</p><p>[<a href="http://www.bailis.org/blog/linearizability-versus-serializability/]">http://www.bailis.org/blog/linearizability-versus-serializability/]</a></p><p><strong>使用场景:</strong></p><ul><li>Locking and leader election: They use consensus algorithms to implement linearizable operations in a fault-tolerant way</li><li>Constraints and uniqueness guarantees</li><li>Cross-channel timing dependencies</li></ul><h3><span id="implementing-linearizable-system">Implementing Linearizable System</span></h3><p>The most common approach to making a system fault-tolerant is to use replication? <code>怎么说</code></p><ul><li><p>Single-leader replication(potentially linearizable): If you make reads from the leader, or from synchronously updated followers, they have the potential to be linearizable.</p></li><li><p>Consensus algorithms(linearizable): consensus protocols contain measures to prevent split brain and stale replicas.</p></li><li><p>Multi-leader replication(not linearizable): because they concurrently process writes on multiple nodes and asynchronously replicate them to other nodes.</p></li><li><p>Leaderless replication(probably not linearizable): sometimes claim that you can obtain “strong consistency” by requiring quorum reads and writes (w + r &gt; n)</p></li></ul><p>简单的使用 quorums,即使满足 w + r &gt; n, 也不一定是 linearizable, 如:</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p60" alt="84bad03c89d979d3cab000ce7b8e47c2.png"></p><h3><span id="the-cost-of-linearizability">The Cost of Linearizability</span></h3><p><strong>The CAP theorem:</strong><br>一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。</p><p>CAP 的定义比较局限,The CAP theorem as formally defined is of very narrow scope: it only considers one consistency model (namely linearizability) and one kind of fault (network partitions,vi or nodes that are alive but disconnected from each other). It doesn’t say anything about network delays, dead nodes, or other trade-offs. </p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p61" alt="c6731ccbcc5f3584f627b3015ae85e29.png"></p><p><strong>Linearizability and network delays:</strong><br>A faster algorithm for linearizability does not exist, but weaker consistency models can be much faster, so this trade-off is important for latency-sensitive systems.</p><h2><span id="ordering-guarantees">Ordering Guarantees</span></h2><p>It turns out that there are deep connections between ordering, linearizability, and consensus.</p><h3><span id="ordering-and-causality">Ordering and Causality</span></h3><p>Ordering helps preserve causality:</p><ul><li>causal dependency: 比如事件的依赖顺序</li><li>happened before relationship</li><li>Cross-channel timing dependencies</li><li>…</li></ul><p><code>Causality imposes an ordering</code> on events,These chains of causally dependent operations define the causal order in the system—i.e., what happened before what.</p><h5><span id="the-causal-order-is-not-a-total-order">The causal order is not a total order</span></h5><p><code>Causality:</code> 在 Casual 中没有依赖的操作可以并发执行,因此这些操作无法比较,所以 Casual 是 partial order(偏序关系).</p><p><code>Linearizability:</code> In a linearizable system, we have a total order of operations. Therefore, according to this definition, there are no concurrent operations in a linearizable datastore.</p><h5><span id="linearizability-is-stronger-than-causal-consistency">Linearizability is stronger than causal consistency</span></h5><p><code>Linearizability implies causality</code> is what makes linearizable systems simple to understand and appealing.</p><p><code>Causal consistency</code> is the strongest possible consistency model that does not slow down due to network delays, and remains available in the face of network failures.</p><h5><span id="capturing-causal-dependencies">Capturing causal dependencies</span></h5><p>In order to maintain causality, you need to know which operation happened before which other operation.</p><p>In order to determine causal dependencies, we need some way of describing the “knowledge” of a node in the system.</p><p>Causal consistency goes further: it needs to track causal dependencies across the entire database, not just for a single key</p><p>In order to determine the causal ordering, the database needs to know which version of the data was read by the application</p><h3><span id="sequence-number-ordering">Sequence Number Ordering</span></h3><p>使用 logical clock 给 event 编号,we can use sequence numbers or timestamps to order events, and they provide a total order.</p><p>We can create equence numbers in a total order that is consistent with causality,先发生的 event 的 number 更小.</p><h5><span id="lamport-timestamps-保证-causality">Lamport timestamps: 保证 causality</span></h5><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p67" alt="f3de2710d844f15e67fb2f831eadcf2b.png"></p><p>Each node has a <code>unique identifier</code>,and each node keeps a <code>counter</code> of the number of operations it has processed. The Lamport timestamp is then simply a pair of (counter, node ID). <strong>It provides total ordering.</strong></p><p>原理解释: </p><ul><li>[<a href="https://jameshfisher.com/2017/02/12/what-are-lamport-timestamps/]">https://jameshfisher.com/2017/02/12/what-are-lamport-timestamps/]</a></li><li>[<a href="https://www.cnblogs.com/bangerlee/p/5448766.html]">https://www.cnblogs.com/bangerlee/p/5448766.html]</a></li></ul><h3><span id="total-order-broadcast">Total Order Broadcast</span></h3><blockquote><p>This idea of knowing when your total order is <code>finalized</code> is captured in the topic of total order broadcast.</p></blockquote><p>Total order broadcast is usually described as a <code>protocol for exchanging messages</code> between nodes, Two safety properties always be satisfied:</p><ol><li>Reliable delivery: msg 需要被 delivered 到所有 node</li><li>Messages are delivered to every node in the same order.</li></ol><blockquote><p>This is no coincidence: it can be proved that a linearizable compare-and-set (or increment-and-get) register and total order broadcast are both equivalent to consensus. That is, if you can solve one of these problems, you can transform it into a solution for the others. This is quite a profound and surprising insight!</p></blockquote><h2><span id="distributed-transactions-and-consensus">Distributed Transactions and Consensus</span></h2><p>Atomic commit,即保证分布式事务的原子性,需要依赖 consensus algo,2PC is a kind of consensus algorithm, which solving atomic commit.  </p><h3><span id="atomic-commit-and-two-phase-commit2pc">Atomic Commit and Two-Phase Commit(2PC)</span></h3><p>Atomicity prevents failed transactions from littering the database with half-finished results and half-updated state. </p><h4><span id="from-single-node-to-distributed-atomic-commit">From single-node to distributed atomic commit</span></h4><p><code>存储硬件层面保证:</code> Thus, it is a single device (the controller of one particular disk drive, attached to one particular node) that makes the commit atomic.</p><p><code>节点层面保证:</code> A node must only commit once it is certain that all other nodes in the transaction are also going to commit, A transaction commit must be irrevocable。</p><p><code>应用层面保证:</code> However, from the database’s point of view this is a separate transaction, and thus any <code>cross-transaction correctness</code> requirements are the application’s problem</p><h4><span id="introduction-to-two-phase-cmmit"></span></h4><p>Two-phase commit is an algorithm for achieving atomic transaction commit across multiple nodes—i.e., to ensure that either all nodes commit or all nodes abort.</p><p>在分布式系统里，每个节点都可以知晓自己操作的成功或者失败，却无法知道其他节点操作的成功或失败。当一个事务跨多个节点时，为了保持事务的原子性与一致性，需要引入一个协调(Coordinator)来统一掌控所有参与者(Participant)的操作结果，并指示它们是否要把操作结果进行真正的提交或者回滚.</p><p>2PC顾名思义分为两个阶段，其实施思路可概括为：</p><ul><li>投票阶段(voting phase): 参与者将操作结果通知协调者；</li><li>提交阶段(commit phase): 收到参与者的通知后，协调者再向参与者发出通知，根据反馈情况决定各参与者是否要提交还是回.</li></ul><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p62" alt="5251bd138b3207f607f3ee80702d1180.png"></p><p>Much of the performance cost inherent in two-phase commit is due to the additional disk forcing (fsync) that is required for crash recovery, and the additional network round-trips.</p><h4><span id="coordinator-failure">Coordinator failure</span></h4><p>2PC can become stuck waiting for the coordinator to recover.</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p64" alt="0120482c7ee1cfc25bee2e7e35f012b7.png"></p><p>The only way 2PC can complete is by waiting for the coordinator to recover. This is why the coordinator must write its commit or abort decision to a transaction log on disk before sending commit or abort requests to participants:when the coordinator recovers, it determines the status of all in-doubt transactions by reading its transaction log. Any transactions that don’t have a commit record in the coordinator’s log are aborted. Thus, the commit point of 2PC comes down to a regular single-node atomic commit on the coordinator.</p><h3><span id="distributed-transactions-in-practice">Distributed Transactions in Practice</span></h3><p>Two types of distributed transactions are often conflated:</p><ul><li>Database-internal distributed transactions: work well as usual</li><li>Heterogeneous distributed transactions: more challenge</li></ul><h4><span id="exactly-once-message-processing">Exactly-once message processing</span></h4><p>Thus, by atomically committing the message and the side effects of its processing, we can ensure that the message is effectively processed <code>exactly once</code>, even if it required a few retries before it succeeded.</p><p>Such a distributed transaction is only possible if all systems affected by the transaction are able to use the same atomic commit protocol.</p><h4><span id="xa-transaction">XA transaction</span></h4><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p65" alt="f91a083d126ff81782b10b138c9080f9.gif"></p><p>The transaction coordinator implements the XA API.</p><h4><span id="holding-locks-while-in-doubt">Holding locks while in doubt</span></h4><p>The database cannot release those locks until the transaction commits or aborts, Therefore, when using two-phase commit, a transaction must hold onto the locks throughout the time it is in doubt.</p><p>This can cause large parts of your application to become unavailable until the in-doubt transaction is resolved.</p><h4><span id="recovering-from-coordinator-failure">Recovering from coordinator failure</span></h4><p>Orphaned in-doubt transactions(如transaction log lost) cannot be resolved automatically, so they sit forever in the database, holding locks and blocking other transactions,只能通过管理员手动解决.</p><p>Many XA implementations have an emergency escape hatch called heuristic decisions: allowing a participant to unilaterally decide to abort or commit an in-doubt transaction without a definitive decision from the coordinator.</p><h4><span id="limitations-of-distributed-transactions">Limitations of distributed transactions</span></h4><p>对于 XA transactions, the key realization is that the transaction coordinator is itself a kind of database (in which transaction outcomes are stored), and so it needs to be approached with the same care as any other important database.</p><h3><span id="fault-tolerant-consensus">Fault-Tolerant Consensus</span></h3><p><strong>思想:</strong> Everyone decides on the same outcome, and once you have decided, you cannot change your mind, a consensus algorithm must satisfy the following properties:</p><ul><li>Uniform agreement: No two nodes decide differently</li><li>Integrity: No node decides twice.</li><li>Validity</li><li>Termination: the idea of <code>fault tolerance</code>: 当有 node crash,也可以达成决策</li></ul><p><strong>Fault Tolerance:</strong></p><ul><li>为保证 termination,需要假设一旦 node crash, it suddenly disappears and <code>never comes back</code>, 以避免无限等待 node recover.</li><li>为保证 termination, 可以使用 <code>quorum</code> 来允许部分 node crash.</li><li>系统一定保证 safety properties,所以 Termination 不满足(如大量 node crash)也不会使系统做出错误的决策。</li></ul><h4><span id="consensus-algorithm-and-total-order-broadcast">Consensus algorithm and total order broadcast</span></h4><p>Consensu algorithm: vsr, paxos, raft, zab…</p><p>这些算法不直接使用上述 Consensus 模型,而是 they decide on a <code>sequence of values</code>, which makes them <code>total order broadcast</code> algorithms.</p><p>So, total order broadcast is equivalent to <code>repeated rounds of consensus</code> (each consensus decision corresponding to one message delivery).</p><p>例子: [<a href="https://www.cnblogs.com/j-well/p/7061091.html]">https://www.cnblogs.com/j-well/p/7061091.html]</a></p><h5><span id="如何选举-leader">如何选举 leader:</span></h5><p>Consensus algo 使用 leader,但是不保证 leader 唯一,所以需要解决选主问题:</p><p>当有多个 leader 时候,use a leader in some form or another, but they don’t guarantee that the leader is unique.</p><p>Node 为了确定自己是 leader,每次操作前需要举行投票确认自己的身份,因此 we have two rounds of voting: once to choose a leader, and a second time to vote on a leader’s proposal.</p><p>Consensus algorithms define a recovery process by which nodes can get into a consistent state after a new leader is elected, ensuring that the safety properties are always met.</p><h4><span id="limitations-of-consensus">Limitations of consensus</span></h4><ul><li>每次 proposal votes is a kind of synchronous replication. <code>影响性能</code></li><li>因为要进行 majority votes,所以对机器数量有要求(如:the remaining two out of three form a majority),如果发生 split brain,部分机器就会变得不可用。</li><li>Most consensus algorithms assume a fixed set of nodes that participate in voting, which means that you can’t just add or remove nodes in the cluster.</li><li>Consensus systems generally rely on timeouts to detect failed nodes. 在网络不好时候可能导致频繁的选主.</li><li>Sometimes, consensus algorithms are particularly sensitive to network problems.</li></ul><h3><span id="membership-and-coordination-services">Membership and Coordination Services</span></h3><p>ZooKeeper 使用场景: </p><ul><li>Linearizable atomic operations</li><li>total order broadcast</li><li>Failure detection</li><li>Change notifications</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#&quot;&gt;?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#summary&quot;&gt;Summary&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#consistent&quot;&gt;Consistent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a hr</summary>
      
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="ddia" scheme="http://example.com/tags/ddia/"/>
    
  </entry>
  
  <entry>
    <title>Part 2: CHAPTER 8 The Trouble with Distributed Systems</title>
    <link href="http://example.com/2019/11/26/Part-2-CHAPTER-8-The-Trouble-with-Distributed-Systems/"/>
    <id>http://example.com/2019/11/26/Part-2-CHAPTER-8-The-Trouble-with-Distributed-Systems/</id>
    <published>2019-11-26T06:33:34.000Z</published>
    <updated>2022-11-25T07:21:17.323Z</updated>
    
    <content type="html"><![CDATA[<p>toc: true</p><h2><span id>?</span></h2><ul><li>what <code>degree</code> they are avoidable</li><li>how to think about the <code>state</code> of a distributed system</li><li>how to <code>reason about</code> things that have happened</li></ul><h2><span id="summary">Summary</span></h2><p>不同于单机,分布式系统中问题是无法避免的,本节主要探讨分布式系统中会遇到的以下问题:</p><ul><li>network 问题,比如网络不通导致节点之间的通信问题</li><li>clock 问题,如:不同 node 的 clock 不同步</li><li>process 问题,如: process may pause for a substantial amount of time at any point in its execution</li></ul><blockquote><p><code>Partial failure</code>: In a distributed system, there may well be some parts of the system that are broken in some unpredictable way, even though other parts of the system are working fine.</p></blockquote><blockquote><p>partial failure 是不可预测的,This <code>nondeterminism</code> and possibility of partial failures is what makes distributed systems hard to work with。</p></blockquote><p>单机和 supercomputer 面对 partial failure 时简单让整个系统崩溃重启就行,这是由于应用场景和硬件设计决定的。对于分布式系统,通常由许多跨地域的普通机器通过以太网进行组织,并为用户提供线上服务,因此出现错误时候简单的重启系统是不可接受的。所以 If we want to make distributed systems work, we must accept the possibility of partial failure and build fault-tolerance mechanisms into the software.</p><p>分布式系统中 <code>partial failure</code> 无法避免,因此需要 <code>fault-tolerance 机制</code></p><h2><span id="unreliable-networks">Unreliable Networks</span></h2><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p50" alt="ac94490f520505608ec2c4b33fe84438.png"></p><p>分布式系统通常采用 shared-nothing 架构, node 之间只能通过网络通信。通常使用的网络是 asynchronous packet networks(如因特网,以太网).</p><p>Async network 无法保证数据交付和交付时效,所以会导致以下问题:</p><ul><li>request lost</li><li>request 延迟</li><li>The remote node may have failed or 无法服务。</li><li>response lose</li><li>response 延迟</li></ul><p>The usual way of handling this issue is a <code>timeout</code>.</p><p>在实际使用中,由于系统和人为因素,网络问题总是无法避免。However, you do need to know how your software reacts to network problems and ensure that the system can recover from them. It may make sense to deliberately trigger network problems and test the system’s response.</p><h3><span id="detecting-faults">Detecting Faults</span></h3><p>Many systems need to automatically detect faulty nodes。</p><p>In some specific circumstances you might get some feedback to explicitly tell you that something is not working</p><p>If you want to be sure that a request was successful, you need a positive response from the application itself </p><p><code>but in general you have to assume that you will get no response at all. You can retry a few times</code></p><h3><span id="timeouts-and-unbounded-delays">Timeouts and Unbounded Delays</span></h3><p>如果以 timout 作为 fail 机制,Timeout 如何选取,过长过短都会有问题。</p><p>如果系统保证 request 和 reponse 的最大时间,那么可以根据这些设置 timeout, 可惜多数系统并不做这种保证。 </p><p>Prematurely declaring a node dead is problematic: </p><p>2d + r would be a reasonable timeout to use.</p><p>很多系统对 request 交付和 response 的最大时间是不做保证的。</p><blockquote><p>For failure detection, it’s not sufficient for the system to be fast most of the time: if your timeout is low, it only takes a transient spike in round-trip times to throw the system off-balance.</p></blockquote><h4><span id="network-congestion拥塞-and-queueing">Network congestion(拥塞) and queueing</span></h4><p>Similarly, the variability of packet delays on computer networks is most often due to queueing:</p><ul><li>比如大量请求一个 node 导致网络拥塞,交换器在队列满后会丢弃后续的数据,这需要 resent request.</li><li>request packet 到 os 时,如果所有 cpu busy, packet 需要排队。</li><li>In virtualized environments</li><li>TCP performs flow control: This means additional queueing at the sender before the data even enters the network.</li></ul><p>In public clouds and multi-tenant datacenters,因为 resource 都是共享的,所以资源缺乏管理的时候,就容易发生拥塞</p><p>In such environments, you can only choose timeouts experimentally:</p><p>Even better, rather than using configured constant timeouts, systems can continually measure response times and their variability (jitter), and automatically adjust timeouts according to the observed response time distribution.</p><h3><span id="synchronous电路交换-versus-asynchronous分组交换-networks">Synchronous(电路交换) Versus Asynchronous(分组交换) Networks</span></h3><p><strong>电路交换</strong>: 如传统电话线路,通信时端到端建立连接,并且独占带宽资源。<br>好处:可以建立可靠的,保证最大递交延迟的通信链路<br>坏处:由于带宽独占,资源被静态切分导致资源利用率不高</p><p><strong>分组交换</strong>:如 Ethernet 和 IP 网,带宽资源动态分配<br>好处:更高的资源利用率<br>坏处:会带来拥塞问题</p><p>而分布式应用通过 ip 网络通信,所以 queuing 问题无法避免。所以:Consequently, there’s no “correct” value for timeouts they need to be determined experimentally.</p><p>Ethernet and IP are packet-switched protocols, which suffer from queueing and thus unbounded delays in the network. 所以无法构筑 establish a guaranteed maximum round-trip time 网络.</p><p>Why do datacenter networks and the internet use packet switching? The answer is that they are optimized for bursty traffic. 使用因特网,doesn’t have any particular bandwidth requirement we just want it to complete as quickly as possible.</p><p>TCP dynamically adapts the rate of data transfer to the available network capacity.</p><blockquote><p>With careful use of quality of service (QoS, prioritization and scheduling of packets) and admission control (rate-limiting senders), it is possible to emulate circuit switching on packet networks, or provide statistically bounded delay.</p></blockquote><h2><span id="unreliable-clocks">Unreliable Clocks</span></h2><p>还是网络问题导致的通信时延让 clock 问题变得棘手。由于每个 node 上 clock 的误差,所以 Time-of-Day Clock 和 monotonic clock 都无法用来标识 event 发生顺序,需要使用 logical clock.</p><blockquote><p>It is possible to synchronize clocks to some degree: the most commonly used mechanism is the Network Time Protocol (NTP), which allows the computer clock to be adjusted according to the time reported by a group of servers.</p></blockquote><h3><span id="monotonic-versus-time-of-day-clocks">Monotonic Versus Time-of-Day Clocks</span></h3><h4><span id="time-of-day-clocks">Time-of-day clocks</span></h4><p>it returns the current date and time according to some calendar </p><p>time-of-day 使用 ntp 进行时间同步,当其和 ntp server 不一致时,会强制重置本地 local clock, These jumps, as well as the fact that they often ignore leap seconds, make time-of-day clocks unsuitable for measuring elapsed time.</p><h4><span id="monotonic-clocks">Monotonic clocks</span></h4><blockquote><p>A monotonic clock is suitable for measuring a duration (time interval), The name comes from the fact that they are guaranteed to always move forward (whereas a time-of-day clock may jump back in time).</p></blockquote><p>the absolute value of the clock is meaningless. 因为 monotonic clocks 不存在在不同节点之间同步的问题,所以在分布式系统使用其来衡量 elaspsed time 是很好的.</p><h4><span id="clock-synchronization-and-accuracy">Clock Synchronization And Accuracy</span></h4><p>hardware clocks and NTP can be fickle beasts</p><p>If your NTP daemon is misconfigured, or a firewall is blocking NTP traffic, the clock error due to drift can quickly become large.</p><h4><span id="relying-on-synchronized-clocks">Relying on Synchronized Clocks</span></h4><p>Robust software needs to be prepared to deal with incorrect clocks.</p><p>Part of the problem is that incorrect clocks easily go unnoticed</p><p>Thus, if you use software that requires synchronized clocks, it is essential that you also carefully monitor the clock offsets between all the machines. </p><h5><span id="timestamps-for-ordering-events">Timestamps for ordering events</span></h5><p>由于网络问题等,各个 node 上的 physical lock 之间存在差值,所以 分布式环境下使用 physical lock(time-of-day and monotonic clocks) 来标识 event 的发生顺序是无法保证正确性的。所以需要引入 logical clocks which are based on incrementing counters,are a safer alternative for ordering events</p><h5><span id="clock-readings-have-a-confidence-interval">Clock readings have a confidence interval</span></h5><p>通过 time-of-day clock 获取的时间往往在一个误差范围内 Thus, it doesn’t make sense to think of a clock reading as a point in time—it is more like a range of times。The uncertainty bound can be calculated based on your time source. </p><h5><span id="synchronized-clocks-for-global-snapshots">Synchronized clocks for global snapshots</span></h5><p>The most common implementation of snapshot isolation requires a monotonically increasing transaction ID.</p><p>在分布式环境下实现 snapshot isolation 时,由于 clock 之间的不一致,实现一个 monotonically increasing transaction ID 比较困难,甚至 With lots of small, rapid transactions, creating transaction IDs in a distributed system becomes an untenable bottleneck.</p><p>在 google spanner 中,使用 confidence time interval 来实现 monotonically increasing transaction ID. In order to keep the wait time as short as possible, Spanner needs to keep the clock uncertainty as small as possible; for this purpose, Google deploys a GPS receiver or atomic clock in each datacenter, allowing clocks to be synchronized to within about 7 ms</p><p><code>google spanner 怎么实现的?</code></p><h3><span id="process-pauses">Process Pauses</span></h3><p>在分布式环境中, thread 可能会 pause so long, 比如 gc。由于在分布式系统中 has no shared memory, only messages sent over an unreliable network,所以单机中使用的并发机制如信号量,锁也都无法使用。</p><p>因此 A node in a distributed system <code>must assume</code> that its execution can be paused for a significant length of time at any point, even in the middle of a function</p><h4><span id="response-time-gurantees怎么解决">Response time gurantees(怎么解决?)</span></h4><ol><li><p>在一些要求实时的系统中, there is a specified deadline by which the software must respond; if it doesn’t meet the deadline, that may cause a failure of the entire system. These are so-called hard real-time systems.</p></li><li><p>实现实时系统: Providing real-time guarantees in a system requires support from all levels of the software stack。For these reasons, developing real-time systems is <code>very expensive</code>, and they are most commonly used in safety-critical embedded devices. Moreover, “real-time” is not the same as “high-performance”—in fact, real-time systems may have lower throughput, since they have to prioritize timely responses above all else</p></li><li><p>所以: For most server-side data processing systems, real-time guarantees are simply not economical or appropriate. Consequently, these systems must suffer the pauses and clock instability that come from operating in a non-real-time environment.</p></li></ol><h4><span id="limiting-the-impact-of-gc">Limiting the impact of gc</span></h4><p>An emerging idea is to treat GC pauses like brief planned outages of a node, and to let other nodes handle requests from clients while one node is collecting its garbage. This trick hides GC pauses from clients and reduces the high percentiles of response time. Some latency-sensitive financial trading systems use this approach.</p><p>A variant of this idea is to use the garbage collector only for short-lived objects (which are fast to collect) and to restart processes periodically, before they accumulate enough long-lived objects to require a full GC of long-lived objects</p><p>These measures cannot fully prevent garbage collection pauses, but they can usefully reduce their impact on the application.</p><h2><span id="knowledge-truth-and-lies">Knowledge, Truth, and Lies</span></h2><blockquote><p>which distributed systems are different from programs running on a single computer: there is no shared memory, only message passing via an unreliable network with variable delays, and the systems may suffer from partial failures, unreliable clocks, and processing pauses.</p></blockquote><blockquote><p>A node in the network cannot know anything for sure—it can only make guesses based on the messages it receives (or doesn’t receive) via the network. A node can only find out what state another node is in (what data it has stored, whether it is correctly functioning, etc.) by exchanging messages with it.</p></blockquote><p>In a distributed system, we can state the assumptions we are making about the behavior (the system model) and design the actual system in such a way that it meets those assumptions。</p><p>由于分布式系统中,节点只能依赖网络传递消息来进行状态判断,导致网络本身的问题和系统的问题无法区分。鉴于底层(os,network)等的不可靠,只能假设这些不可靠因素存在,在上层构筑可靠的系统。</p><h3><span id="the-truth-is-defined-by-the-majority">The Truth Is Defined by the Majority</span></h3><p>分布式中,单个节点不可信,所以要依赖多个节点进行仲裁</p><p>A distributed system cannot exclusively rely on a single node, because a node may fail at any time, potentially leaving the system stuck and unable to recover. Instead, many distributed algorithms rely on a <code>quorum</code>, that is, voting among the nodes.</p><p>仲裁策略:<br>The individual node must abide by the quorum decision and step down.A majority quorum allows the system to continue working if individual nodes have failed</p><h4><span id="the-leader-and-the-clock">The leader and the clock</span></h4><p>Frequently, a system requires there to be <code>only one</code> of some thing.使用仲裁,这些 only one 也不一定可以被保证。如 <code>the chosen one</code> 问题:</p><p>If a node continues acting as the chosen one, even though the majority of nodes have declared it dead, it could cause problems in a system that is not carefully designed.</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p48" alt="5f8c2ea278de3c42e96fbfadf7fac22f.png"></p><h4><span id="fencing-tokens">Fencing tokens</span></h4><p>使用 fencing 技术来解决 <code>the chosen one</code> 问题.</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p49" alt="01e3d4c1ab7ca4027e38d137c0062956.png"></p><p>Note that this mechanism requires the resource itself to take an active role in checking tokens by rejecting any writes with an older token than one that has already been processed—it is not sufficient to rely on clients checking their lock status themselves.</p><p>In server side, it is a good idea for any service to protect itself from accidentally abusive clients.</p><h3><span id="byzantiine-faults">Byzantiine Faults</span></h3><blockquote><p>拜占庭将军问题实际上指的是在一个有 n 个节点的集群内，有 t 个节点可能发生任意错误的情况下，如果 n &lt;&#x3D; 3t，一个正确的 consensus 不可能达成<br>假设节点总数是N，叛徒将军数为F，则当 N &gt;&#x3D; 3F+1 时，问题才有解，共识才能达成，这就是Byzantine Fault Tolerant（BFT）算法。</p></blockquote><p>在仲裁的时候,如果 node lie 那么就会有拜占庭将军问题,在分布式系统中,所有 node 都是自己设置的,可以不必考虑拜占庭问题,在区块链等对等网络中需要考虑。</p><p>Although we assume that nodes are generally honest, it can be worth adding mechanisms to software that guard against weak forms of “lying”, for example, invalid messages due to hardware issues, software bugs, and misconfiguration.</p><h3><span id="system-model-and-reality">System Model and Reality</span></h3><blockquote><p>system model, which is an abstraction that describes what things an algorithm may assume.</p></blockquote><p><strong>To timing assumptions model:</strong></p><ul><li>Synchronous model: it just means you know that network delay, pauses, and clock drift will never exceed some fixed upper bound. 由于现实中 unbounded delays 无法避免,所以这个 model 不切实际。</li><li>Partially synchronous model: Partial synchrony means that a system behaves like a synchronous system most of the time, but it sometimes exceeds the bounds for network delay, process pauses, and clock drift。符合实际情况</li><li>Asynchronous model: In this model, an algorithm is not allowed to make any timing assumptions—in fact, it does not even have a clock (so it cannot use timeouts).</li></ul><p><strong>Node Failure model:</strong></p><ul><li>Crash-stop faults: 只有 crash(he node may suddenly stop responding at any moment) 导致 node fail, crash 后无法恢复</li><li>Crash-recorvery faults: node crash 后可以通过 stable storage 存储的数据恢复,而内存中的数据会丢失</li><li>Byzantine (arbitrary) faults</li></ul><p><code>crash-recovery faults is generally the most useful model.</code></p><h5><span id="correctness-of-an-algorithms">Correctness of an algorithms</span></h5><p>To define what it means for an algorithm to be correct, we can describe its <code>properties</code>.</p><p>An algorithm is correct in some system model if it always satisfies its properties in all situations that we assume may occur in that system mode</p><p>但是最坏的情况下,如 all nodes crash 或者 all network delay infinitely long,算法将失效</p><h5><span id="safety-and-liveness">Safety and liveness</span></h5><p>To clarify the situation, it is worth distinguishing between two different kinds of properties: <code>safety and liveness properties</code><br>An advantage of distinguishing between safety and liveness properties is that it helps us deal with difficult system models, with liveness properties we are allowed to make caveats</p><p><strong>Safety:</strong> something <code>bad</code> will never happen<br><strong>Liveness:</strong> something <code>good</code> will must happen (but we don’t know when)</p><p><a href="https://zhuanlan.zhihu.com/p/37864854">https://zhuanlan.zhihu.com/p/37864854</a></p><h5><span id="mapping-system-models-to-the-real-world">Mapping system models to the real world</span></h5><p>The system model is a simplified abstraction of reality,理想很丰满,现实很骨感,算法模型做了一些假设,但是现实中这些假设会被打破,还是需要做容错处理</p><p>Model 的作用(推断证明): They are incredibly helpful for distilling down the complexity of real systems to a manageable set of faults that we can reason about, so that we can understand the problem and try to solve it systematically.</p><p>Theoretical analysis and empirical testing are equally important.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;toc: true&lt;/p&gt;
&lt;h2&gt;&lt;span id&gt;?&lt;/span&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;what &lt;code&gt;degree&lt;/code&gt; they are avoidable&lt;/li&gt;
&lt;li&gt;how to think about the &lt;code&gt;state&lt;</summary>
      
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="ddia" scheme="http://example.com/tags/ddia/"/>
    
  </entry>
  
  <entry>
    <title>Part 2: CHAPTER 7 Transactions</title>
    <link href="http://example.com/2019/11/17/Part-2-CHAPTER-7-Transactions/"/>
    <id>http://example.com/2019/11/17/Part-2-CHAPTER-7-Transactions/</id>
    <published>2019-11-17T06:32:47.000Z</published>
    <updated>2022-11-25T06:34:47.263Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h2><span id="reference">Reference</span></h2><ul><li><a href="http://www.zhai14.com/blog/strenghen-comprehension-on-dirty-read-and-phantom.html">http://www.zhai14.com/blog/strenghen-comprehension-on-dirty-read-and-phantom.html</a></li><li><a href="https://www.aneasystone.com/archives/2017/10/solving-dead-locks-one.html">https://www.aneasystone.com/archives/2017/10/solving-dead-locks-one.html</a></li></ul><h2><span id="overview">Overview</span></h2><blockquote><p>A transaction is a way for an application to group several reads and writes together into a logical unit. Conceptually, all the reads and writes in a transaction are executed as one operation: <code>either the entire transaction succeeds (commit) or it fails (abort, rollback)</code></p></blockquote><blockquote><p>Transaction 简化了应用对数据库的访问,使 error handling 变得简单,因为无需考虑 partial failure。</p></blockquote><p>Widely used isolation levels(<code>解决数据库的并发读写问题</code>):</p><ul><li>read committed</li><li>snapshot isolation(repeatable read)</li><li>serialization</li></ul><p>Race conditions:</p><ul><li><p>Dirty reads: 一个 client 读取了另一个 client 尚未提交的写。</p></li><li><p>Dirty writes: 而当事务 A 更新时，事务 A 还没提交，事务 B 就也过来进行更新，覆盖了事务 A 提交的更新数据。Almost all transaction implementations prevent dirty writes.</p></li><li><p>Read skew(Repeatable Read): A client sees different parts of the database at different points in time。snapshot isolation level(MVCC) 可以防止 read skew。</p></li><li><p>Lost updates: read-modify-write cycle 下容易发生,snapshot isolation level 可以防止该问题。</p></li><li><p>Write skew: Only serializable isolation prevents this anomaly.</p></li><li><p>Phantom reads: Snapshot isolation prevents straightforward phantom reads, but phantoms in the context of write skew require special treatment, such as index-range locks.</p></li></ul><p>only serializable isolation protects against all of these issues. We discussed three different approaches to implementing serializable transactions:</p><ul><li><p>Literally executing transactions in a serial order: 如果您可以使每个事务的执行速度非常快，并且事务吞吐量足够低，可以在单个CPU核心上处理，那么这是一个简单而有效的选项。</p></li><li><p>Two-phase locking</p></li><li><p>Serializable snapshot isolation (SSI):It uses an optimistic approach, allowing transactions to proceed without blocking.</p></li></ul><h2><span id="the-slippery-concept-of-a-transaction">The Slippery Concept of a Transaction</span></h2><p>Nosql 牺牲一致性来保证可用性; Relation db 使用 transaction 来保证强一致性。说到底么有孰优孰劣,都是根据场景的 <code>trade-off</code>。</p><h3><span id="the-meaning-of-acid">The meaning of ACID</span></h3><h4><span id="atomicity">Atomicity</span></h4><p>在 ACID 语境下, Atomicity 不是关于并发的原子性,而是: The ability to abort a transaction on error and have all writes from that transaction discarded is the defining feature of ACID atomicity.</p><h4><span id="consistency">Consistency</span></h4><blockquote><p>this idea of consistency depends on the application’s notion of invariants, and it’s the application’s responsibility to define its transactions correctly so that they preserve consistency。</p></blockquote><p>指的是应用程序(不是数据库)需要保证数据读写保证其应用程序的约束条件,以保证一致性。</p><h4><span id="isolatoin处理-concurrency-problems">Isolatoin(处理 concurrency problems)</span></h4><p>Isolation in the sense of ACID means that concurrently executing transactions are isolated from each other: they cannot step on each other’s toes. </p><h4><span id="durability">Durability</span></h4><p>Durability is the promise that once a transaction has committed successfully, any data it has written will not be forgotten, even if there is a hardware fault or the database crashes.</p><h3><span id="single-object-and-multi-object-operations">Single-Object and Multi-Object Operations</span></h3><p>To recap, in ACID, atomicity and isolation describe what the database should do if a client makes several writes within the same transaction.</p><ul><li>Single-object writes</li></ul><p>单条数据的读写也面临容错问题,比如当一条 10K 的 json 写入一半时网络断掉,所以对于 single-object, 存储也要提供 atomicity(可以用 log 实现) 和 isolation(可以用加锁的方式实现)。</p><ul><li>The need for multi-object transactions</li></ul><p>single-object 事物无法满足所有的场景,如更新数据的时候需同步更新二级索引,所以 multi-object transaction 是需要的。</p><ul><li>Handling errors and aborts</li></ul><p>Retrying an aborted transaction is a simple and effective error handling mechanism, 但是也会导致很多问题,比如不断重试对 server 造成压力。</p><h2><span id="weak-isolation-levels">Weak Isolation Levels</span></h2><p>Serializable isolation means that the database guarantees that transactions have the same effect as if they ran serially (i.e., one at a time, without any concurrency)</p><p>但是 Serializable isolation has a performance cost, 所以 It’s therefore common for systems to use weaker levels of isolation, which protect against some concurrency issues, but not all。</p><h3><span id="read-committed">Read Committed</span></h3><p><code>保证</code>:</p><ul><li>no dirty reads: 脏读会读取到不一致的数据</li><li>no dirty writes: usually by delaying the second write until the first write’s transaction has committed or aborted.</li></ul><p><code>实现</code>:<br>使用 row-level lock 实现,当一个 transaction 修改一个 object(row or document) 时,必须先获取这个 object 的锁直到 transaction 完成才释放。在 transaction 期间,其他 transaction 会读取到旧值。</p><h3><span id="snapshot-isolation-and-repeatable-read">Snapshot Isolation and Repeatable Read</span></h3><p>使用 Snapshot Isolation 来解决 repeatable read 的问题。</p><blockquote><p>The idea is that each transaction reads from <code>a consistent snapshot</code> of the database,Snapshot isolation is a boon for long-running, read-only queries such as backups and analytics.</p></blockquote><h4><span id="实现-multi-version-concurrency-control-mvcc"><code>实现</code>: <code>multi-version concurrency control (MVCC)</code>:</span></h4><blockquote><p><a href="https://www.cnblogs.com/luchangyou/p/11321607.html">https://www.cnblogs.com/luchangyou/p/11321607.html</a></p></blockquote><ul><li>写: use write locks to prevent dirty writes</li><li>读: a key principle of snapshot isolation is readers never block writers, and writers never block readers。所以 the database must potentially keep several different committed versions of an object 来实现 snapshot 的效果。</li></ul><h5><span id="visibility-rules-for-observing-a-consistent-snapshot">Visibility rules for observing a consistent snapshot</span></h5><p>Put another way, an object is visible if both of the following conditions are true:</p><ul><li>At the time when the reader’s transaction started, the transaction that created the object had already committed.</li><li>The object is not marked for deletion, or if it is, the transaction that requested deletion had not yet committed at the time when the reader’s transaction started.</li></ul><h5><span id="indexes-and-snapshot-isolation">Indexes and snapshot isolation</span></h5><ul><li><p>have the index simply point to all versions of an object and require an index query to filter out any object versions that are not visible to the current transaction</p></li><li><p>use an append-only&#x2F;copy-on-write variant that does not overwrite pages of the tree when they are updated, but instead creates a new copy of each modified page.</p></li><li><p>With append-only B-trees, every write transaction (or batch of transactions) creates a new B-tree root, and a particular root is a consistent snapshot of the database at the point in time when it was created.</p></li></ul><h3><span id="preventing-lost-updates">Preventing Lost Updates</span></h3><h5><span id="atomic-write-operations">Atomic write operations</span></h5><p><code>实现</code>:</p><ul><li>一种方法是使用排他锁,taking an exclusive lock on the object when it is read so that no other transaction can read it until the update has been applied.</li><li>一种方式是 simply force all atomic operations to be executed on a single thread.</li></ul><h4><span id="explicit-locking">Explicit locking</span></h4><p>如果 db 提供的 atomic write operations 不足, 就需要在应用层面提供锁机制来解决并发写带来的问题。</p><h5><span id="automatically-detecting-lost-updates">Automatically detecting lost updates</span></h5><p>An alternative is to allow them to execute in parallel and, if the transaction manager detects a lost update, abort the transaction and force it to retry its read-modify-write cycle.</p><p>An advantage of this approach is that databases can perform this check efficiently in conjunction with snapshot isolation. </p><h5><span id="compare-and-set">Compare-and-set</span></h5><p>The purpose of this operation is to avoid lost updates by allowing an update to happen only if the value has not changed since you last read it。如:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- This may or may not be safe, depending on the database implementation</span></span><br><span class="line"><span class="keyword">UPDATE</span> wiki_pages <span class="keyword">SET</span> content <span class="operator">=</span> <span class="string">&#x27;new content&#x27;</span> <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">1234</span> <span class="keyword">AND</span> content <span class="operator">=</span> <span class="string">&#x27;old content&#x27;</span>;</span><br></pre></td></tr></table></figure><h3><span id="write-skew-and-phantoms幻读">Write Skew and Phantoms(幻读)</span></h3><blockquote><p>This effect, where a write in one transaction changes the result of a search query in another transaction, is called a <code>phantom</code><br><code>Write skew</code> can occur if two transactions read the same objects, and then update some of those objects (different transactions may update different objects).</p></blockquote><p><strong>怎么解决?</strong></p><ul><li>use a serializable isolation level</li><li>probably to explicitly lock the rows that the transaction depends on</li><li>materializing conflicts: it takes a phantom and turns it into a lock conflict on a concrete set of rows that exist in the database。</li></ul><h2><span id="serializability">Serializability</span></h2><blockquote><p>Serializable isolation: It guarantees that even though transactions may execute in parallel, the end result is the same as if they had executed one at a time, serially, without any concurrency</p></blockquote><p>3 种实现方式:</p><ul><li>Literally executing transactions in a serial order</li><li>Two-phase locking</li><li>Optimistic concurrency control techniques such as serializable snapshot isolation</li></ul><h3><span id="actual-serial-execution">Actual Serial Execution</span></h3><h4><span id="encapsulating-transactions-in-stored-procedures">Encapsulating transactions in stored procedures</span></h4><p>在使用 single-threaded serial transaction 的 db 中,db 和 client 进行交互式的事务非常的低效,所以一般 the application must submit the entire transaction code to the database ahead of time, as a <code>stored procedure</code>. </p><p><code>Serial execution 总结:</code></p><ul><li>Every transaction must be small and fast</li><li>It is limited to use cases where the active dataset can fit in memory·</li><li>Write throughput must be low enough to be handled on a single CPU core。</li><li>Cross-partition transactions are possible,但是很耗资源</li></ul><h3><span id="two-phase-locking2pl">Two-Phase Locking(2PL)</span></h3><p>In 2PL, writers don’t just block other writers; they also block readers and vice versa.</p><p>Two Phase:</p><ul><li>first phase: (while the transaction is executing) is when the locks are acquired</li><li>second phase: (at the end of the transaction) is when all the locks are released.</li></ul><h5><span id="implementation">Implementation</span></h5><p>having a lock on each object in the database. The lock can either be in <code>shared mode</code> or in <code>exclusive mode</code>. 读取的时候获取共享锁,写的时候获取排他锁。可以允许同时多个读,但是读会阻塞写,写会阻塞其他读和写。</p><h5><span id="performance">Performance</span></h5><p>For this reason, databases running 2PL can have quite unstable latencies, and they can be very slow at high percentiles if there is contention in the workload.</p><h5><span id="predicate-locks谓词锁">Predicate locks(谓词锁)</span></h5><p>The key idea here is that a predicate lock applies even to objects that do not yet exist in the database, but which might be added in the future (phantoms).</p><p>Index-range locks</p><h3><span id="serializable-snapshot-isolationssi">Serializable Snapshot Isolation(SSI)</span></h3><p>基于 snapshot isolation 技术, SSI adds an algorithm for <code>detecting</code> serialization conflicts among writes and determining which transactions to abort.</p><p>It provides full serializability, but has only a small performance penalty compared to snapshot isolation.</p><p>缺陷: 当有大量事务访问 the same objects,可能会导致大量的事务 abort。<br>优势: 当 contention between transactions is not too high 时,相比悲观并发技术会有更好的性能。而且  Like under snapshot isolation, writers don’t block readers, and vice versa。</p><h4><span id="decisions-based-on-an-outdated-premise">Decisions based on an outdated premise</span></h4><p>2 种 db 检测 query result might have changed 的方式:</p><p><strong>Detecting stale MVCC reads</strong>:<br>When the transaction wants to commit, the database checks whether any of the ignored writes have now been committed. If so, the transaction must be aborted.</p><p>By avoiding unnecessary aborts, SSI preserves snapshot isolation’s support for long-running reads from a consistent snapshot.</p><p><strong>Detecting writes that affect prior reads</strong>:<br>When a transaction writes to the database, it must look in the indexes for any other transactions that have recently read the affected data. it simply notifies the transactions that the data they read may no longer be up to date.</p><h4><span id="performance">Performance</span></h4><p>The rate of aborts significantly affects the overall performance of SSI. </p><p>so SSI requires that read-write transactions be fairly short (long-running read-only transactions may be okay). However, SSI is probably less sensitive to slow transactions than two-phase locking or serial execution.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2&gt;&lt;span id=&quot;reference&quot;&gt;Reference&lt;/span&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.zhai14.com/blog/strenghen-comprehension-on-dirty-rea</summary>
      
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="ddia" scheme="http://example.com/tags/ddia/"/>
    
  </entry>
  
  <entry>
    <title>Part 2: CHAPTER 6 Partitioning</title>
    <link href="http://example.com/2019/10/27/Part-2-CHAPTER-6-Partitioning/"/>
    <id>http://example.com/2019/10/27/Part-2-CHAPTER-6-Partitioning/</id>
    <published>2019-10-27T06:28:55.000Z</published>
    <updated>2022-11-25T06:37:39.461Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="summary">Summary</span></h2><p>Partition 可以结合 Replication, 每个 partition 可以有多个 Replication 以保持高可用,如图:</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p47" alt="4da1c26598524fc627da7e80bf1f53e9.png"></p><blockquote><p>Partition(sharding): partitioning a large dataset into smaller subsets, that each piece of data (each record, row, or document) belongs to <code>exactly one</code> partition.使用 partition 可以分散读写,可以横向扩展。</p></blockquote><p>The main reason for wanting to partition data is <code>scalability</code>: 数据和写入都可以分散到多个机器上去,以避免 hot spots。数据的 split 要合理,避免数据倾斜,同时要考虑 node 上下线的问题。</p><p>2 种 partitioning 的方式:</p><ul><li><p>Key range partitioning:key are sorted,partition 中也按 key 有序存储</p><ul><li>优点: 高效的 range query</li><li>缺点: 访问的 key 相对集中时候的热点问题</li><li>rebalance 策略: dynamically by splitting the range into two subranges when a partition gets too big.</li></ul></li><li><p>Hash partitioning: 将 key hash 到对应的 partition,key 是无的序,从而换取更均匀的数据分布</p><ul><li>优点: 更均匀的数据分布</li><li>缺点: 低效的 range query</li><li>rebalance 策略: common to create a fixed number of partitions in advance, to assign several partitions to each node, and to move entire partitions from one node to another when nodes are added or removed</li></ul></li></ul><p>可以混合 2 种 partition 方式: using one part of the key to identify the partition and another part for the sort order.</p><p>Secondary index 的 2 种 partition 方式:</p><ul><li>Document-partitioned indexes (<code>local indexes</code>): 和主键存储在同一个 partition,所以更新时只需更新单个 partition, 但是读取时需要聚集多个 partition 的数据</li><li>Term-partitioned indexes (<code>global indexes</code>): 分散在各个分区中,更新的时候需要更新多个,但是读取的时候只需要读取一个 partition</li></ul><h2><span id="partitionoing-of-key-value-data">Partitionoing of Key-Value Data</span></h2><p>Our goal with partitioning is to spread the data and the query load evenly across nodes. </p><p>如果 partition 不能平均分配, 就会出现数据倾斜和 hot spot 问题。</p><h4><span id="partitioning-by-key-range">Partitioning by Key Range</span></h4><p>One way of partitioning is to assign a continuous range of keys (from some minimum to some maximum) to each partition</p><p>In order to distribute the data evenly, the partition boundaries need to adapt to the data.</p><p>Within each partition, we can keep keys in sorted order (SSTables and LSM-Trees)</p><p>劣势: 如果频繁访问部分 key,会造成 hot spots 问题。</p><h4><span id="partitioning-by-hash-of-key">Partitioning by Hash of Key</span></h4><p>使用 hash function 对 key 求 hash 值,you can assign each partition a range of hashes (rather than a range of keys), and every key whose hash falls within a partition’s range will be stored in that partition。如图:</p><p><img src="https://notes.shichao.io/dda/figure_6-3_600.png" alt="image"></p><p><code>优势</code>: This technique is good at distributing keys fairly among the partitions. The partition boundaries can be evenly spaced. </p><p><code>劣势</code>: range query 需要读取多个 partitoin,相比于 key range parition,比较低效。</p><h2><span id="partitioning-and-secondary-indexes">Partitioning and Secondary Indexes</span></h2><blockquote><p>A secondary index usually doesn’t identify a record uniquely but rather is a way of searching for occurrences of a particular value.</p></blockquote><blockquote><p>二级索引在关系型数据库中比较普遍。由于实现的复杂性,许多 k,v 存储(如 hbase)避免使用二级索引。搜索引擎(如 es)使用二级索引。</p></blockquote><p>The <code>problem</code> with secondary indexes is that they don’t map neatly to partitions.</p><p>There are two main approaches to partitioning a database with secondary indexes: <code>document-based</code> partitioning and <code>term-based</code> partitioning.</p><h3><span id="partitioning-secondary-indexes-by-documentlocal-index">Partitioning Secondary Indexes by Document(local index)</span></h3><p>In this indexing approach, each partition is completely separate: each partition maintains its own secondary indexes, covering only the documents in that partition.如图:</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p27" alt="14f2449166cc366c4b5a60de76ddd8c6.png"></p><p>优势: 实现简单,写入和更新 index 比较简单高效。<br>劣势: 读取成本高,需要读取所有 partition, Even if you query the partitions in parallel.</p><h3><span id="partitioning-secondary-indexes-by-termglobal-index">Partitioning Secondary Indexes by Term(global index)</span></h3><blockquote><p>Term: 来自全文索引的概念,这里指的是: where the terms are all the words that occur in a document.</p></blockquote><p>global index that covers data in all partitions,如果所有 index 都存储在一台 node 会成为瓶颈,所以 index 也需要 partitioned,可以通过 term 自身(方便 range scan)或者 hash 的方式(可以均匀分散)对 term index 进行 partition。 如图:</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p40" alt="a19496e312343d1bfbd4f20a28025fc0.png"></p><p>好处: 使用索引可以只读取相应的 partition, 提交读取效率。<br>坏处: 因为写入的时候需要更新多个 partition 中的 index,所以写效率降低且复杂。</p><p>In practice, updates to global secondary indexes are often asynchronous, 因此 index 写入后不是立即可见的, 所以需要 distributed transactioon 来保证所有写入 partition 的索引的正确和立即可见。</p><h2><span id="rebalancing-partitions">Rebalancing Partitions</span></h2><blockquote><p>The process of moving load from one node in the cluster to another is called rebalancing.</p></blockquote><p>Rebalancing 需满足:</p><ul><li>将 load(存储,读写 load)公平的分配到集群的机器上。</li><li>Rebalancing 的同时, db 可以继续提供读写服务</li><li>要降低网络和磁盘 io,在 node 间只移动必要的数据。</li></ul><h3><span id="strategies-for-rebalancing">Strategies for Rebalancing</span></h3><p>We need an approach that doesn’t move data around more than necessary.</p><h4><span id="hash-mod-n">hash mod N</span></h4><p>The problem with the mod N approach is that if the number of nodes N changes, most of the keys will need to be moved from one node to another</p><h4><span id="fixed-number-of-partitions">Fixed number of partitions</span></h4><p>使用固定数量的 partitions is operationally simpler,然而选取合适的 partition 数量是非常困难的。而且在增减机器时候也有不必要的数据移动,如图:</p><p>如图:</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p44" alt="a2713cc5f32c187684c32074e2122f3f.png"></p><h4><span id="dynamic-partitioning">Dynamic partitioning</span></h4><p>当 partiton 中数据量增长到一个阈值的时候,可以 split 为 2 个partiton;同时,如果有数据删除,partiiton 变小,可以合并相邻 partition。</p><p><code>优势</code>: the number of partitions adapts to the total data volume</p><p><code>缺陷</code>: 当数据量小的时候被分配到一个 partition 中,开始所有的读写都会打到这个 partition, 为了缓解这个问题,可以预先分配一些 partition,但这需要 know what the key distribution is going to look like。</p><h4><span id="partitioning-proportionally-to-nodes">Partitioning proportionally to nodes</span></h4><p>在以上的 cases 中, the number of partitions is independent of the number of nodes.</p><p>To have a fixed number of partitions per node, this approach also keeps the size of each partition fairly stable.这个方式可以很好的适应数据规模的变化,但是在增减机器 rebanlancing 的时候需要注意避免形成 unfailrly partition.</p><h3><span id="operations-automatic-or-manual-rebalancing">Operations: Automatic or Manual Rebalancing</span></h3><p>自动 rebalancing 十分方便,但是是不可预测的,同时 automation can be dangerous in combination with automatic failure detection, 可能导致级联的错误。因此让人介入 rebalance 是比较好的。</p><h2><span id="request-routing">Request Routing</span></h2><p>service discovery 问题, client 如何知道要访问哪台机器? 有 3 种方式,如图:</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p45" alt="c0d7cd822c95ac299173b2008b7364a9.png"></p><p>Many distributed data systems rely on a separate coordination service such as ZooKeeper to keep track of this cluster metadata,如图:</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p46" alt="fb8752be8a9436d2ed221fa97a0106c5.png"></p><h2><span id="parallel-query-execution">Parallel Query Execution</span></h2><p>The MPP(massively parallel processing) query optimizer breaks this complex query into a number of execution stages and partitions, many of which can be executed in parallel on different nodes of the database cluster。如各种分布式计算引擎: mr, spark, presto.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2&gt;&lt;span id=&quot;summary&quot;&gt;Summary&lt;/span&gt;&lt;/h2&gt;&lt;p&gt;Partition 可以结合 Replication, 每个 partition 可以有多个 Replication 以保持高可用,如图:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;evernote</summary>
      
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="ddia" scheme="http://example.com/tags/ddia/"/>
    
  </entry>
  
  <entry>
    <title>Part 2: CHAPTER 5 Replication</title>
    <link href="http://example.com/2019/09/29/Part-2-CHAPTER-5-Replication/"/>
    <id>http://example.com/2019/09/29/Part-2-CHAPTER-5-Replication/</id>
    <published>2019-09-29T06:27:13.000Z</published>
    <updated>2022-11-25T06:27:53.896Z</updated>
    
    <content type="html"><![CDATA[<h2><span id>?</span></h2><ul><li>Replication 和 partition 如何组合使用?</li><li>如何解决<code>并发</code>问题?</li><li>如何保证 <code>consistency</code>?</li><li>如何提高<code>容错</code>,应对如网络中断, latency spikes 问题</li></ul><h2><span id="summary">Summary</span></h2><p><strong>Replication 是什么?</strong><br>Each node that stores a copy of the database is called a replica.</p><p><strong>Replication 可以解决什么问题?</strong></p><ul><li>High availability</li><li>Disconnected operation: Allowing an application to continue working when there is a network interruption</li><li>Latency: datacenter</li><li>Scalability: 副本所提供的大量的<code>读</code>能力</li></ul><p><strong>主要面临的问题</strong></p><ul><li>容错和并发: It requires carefully thinking about <code>concurrency</code> and about all the things that can go wrong, and dealing with the consequences of those faults.</li><li>并发下的数据<code>一致</code>性</li></ul><p><strong>Three main approaches to replication:</strong></p><ul><li>Single-leader replication: 简单,不需要处理数据冲突</li><li>Multi-leader replication</li><li>Leaderless replication: 和 Multi-leader 容错更好,但是只能提供 <code>very week consistency guarantees</code></li></ul><p><strong>如何解决<code>容错</code>和<code>一致</code>性?</strong></p><p>Replication can be synchronous or asynchronous,which has a profound effect on the system behavior when there is a fault. 比如在 lag increases 和 servers fail 时如何处理?</p><p>一些 <code>consistency model</code> which are helpful for deciding how an application should behave under <code>replication lag</code>:</p><ul><li>Read-after-write consistency</li><li>Monotonic reads</li><li>Consistent prefix reads</li></ul><h2><span id="leaders-and-followerssingle-leader">Leaders and Followers(single-leader)</span></h2><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p59" alt="c274c0e68e7967560857917925462113.png"></p><p>使用 leader-based replication(master–slave replication) 来解决 replication 写入问题的流程:</p><ol><li>进行选主(elect leader)</li><li>leader 写入时,会将数据以 replication log 或者 change stream 的形式发送给 followers, follower 更新本地 replication</li><li>writes are only accepted on the leader (the followers are read-only from the client’s point of view).</li></ol><blockquote><p>This mode of replication is a built-in feature of many relational databases<br>Leader-based replication is not restricted to only databases, 如消息队列也会使用</p></blockquote><h3><span id="syncchronous-versus-asynchronous-replication">Syncchronous Versus Asynchronous Replication</span></h3><h5><span id="synchronous">Synchronous</span></h5><p><code>优势</code>(保证数据一致性):<br>The follower is guaranteed to have an up-to-date copy of the data that is consistent with the leader.</p><p><code>劣势</code>(系统可用性差):<br>如果有 follower 无法响应(如遇到网络问题),那么 the write cannot be processed. The leader must block all writes and wait until the synchronous replica is available again.</p><p>所以所有 followers 都是同步是不现实的,一般使用如 semi-synchronous 方式,至少保证系统中一个 follower 是 sync 的,其他 follower 则是 async 的,This guarantees that you have an up-to-date copy of the data on at least two nodes</p><h5><span id="completely-asynchronous">Completely Asynchronous</span></h5><p><code>如何在并发场景下保证数据一致?</code></p><p><code>优势</code>(可用性高): The leader can continue processing writes, even if all of its followers have fallen behind.</p><p><code>劣势</code>:</p><ul><li><code>写丢失</code>: If the leader fails and is not recoverable, any writes that have not yet been replicated to followers are lost.</li><li><code>不保证写入</code>: A write is not guaranteed to be durable, even if it has been confirmed to the client</li></ul><p>尽管如此,全异步还是被广泛使用,尤其在 there are many followers or if they are geo‐graphically distributed.</p><h3><span id="setting-up-new-followers扩容时的一致性">Setting Up New Followers(扩容时的一致性)</span></h3><p>set up 新 follower 时,如何保证 the <code>new follower</code> has an <code>accurate copy</code> of the leader’s data?</p><ol><li>Take <code>a consistent snapshot</code> of the leader’s database at some point in time—if possible, without taking a lock on the entire database.</li><li>Copy the snapshot to the new follower node.</li><li>The follower connects to the leader and requests <code>all the data changes that have happened since the snapshot</code> was taken.</li></ol><h3><span id="handling-node-outages容错">Handling Node Outages(容错)</span></h3><p>其实就是如何保证 High Availability: Thus, our goal is to keep the system as a whole running despite individual node failures, and to keep the impact of a node outage as small as possible.</p><p><code>所以如何在处理机器不可用问题,以保证高可用?</code></p><h5><span id="follower-failure-catch-up-recovery">Follower failure: Catch-up recovery</span></h5><p>follower 本地保存 <code>data chanage log</code>(received from leader), 可以从 log 中进行恢复, 然后再从 leader 拿到停止时间内的 log 进行重建</p><blockquote><p>the follower can connect to the leader and request all the data changes that occurred during the time when the follower was disconnected</p></blockquote><h5><span id="leader-failure-failover">Leader failure: Failover</span></h5><p>如何处理?</p><ol><li>重新选主</li><li>followers 从新主获取数据</li><li>client 和新 leader 交互</li></ol><p>ha 机制:</p><ol><li><p>Determining that the leader has failed</p></li><li><p>Choosing a new leader:The best candidate for leadership is usually the replica with the <code>most up-to-date data changes from the old leader</code> (to minimize any data loss). Getting all the nodes to agree on a new leader is a <code>consensus problem</code></p></li><li><p>Reconfiguring the system to use the new leader:<br>The system needs to ensure that the old leader becomes a follower and recognizes the new leader.</p></li></ol><p>一些问题:</p><ul><li><p>如果使用异步 replication, new leader 和 old leader 之间可能存在 write 数据的差异, 此时 common solution 是 old leader 丢弃这些 writes. </p></li><li><p>丢弃写入可能会导致和其他外部存储系统数据不一致</p></li><li><p>split brain(有多个 node 认为自己是 leader): data is likely to be lost or corrupted; you can end up with both nodes being shut down</p></li><li><p>合理的 leader 失效 timeout 设置? load spike, network glitch 这些情况需要被综合考虑</p></li></ul><blockquote><p>node failures; unreliable networks; trade-offs around replica consistency, durability, availability and latency are in fact fundamental problems in distributed systems</p></blockquote><h3><span id="implementation-of-replication-logs">Implementation of Replication Logs</span></h3><p>the log is an append-only sequence of bytes containing all writes to the database</p><p>leader 将 log 写到本地,同时发送给 followers, follower 执行 log 来建立和 leader 相同的 replication</p><h5><span id="statement-based-replication">Statement-based replication</span></h5><p>最简单的情况:<br>leader logs <code>every write request(statement)</code> that it executes and sends that statement log to its followers</p><p>缺点:</p><ul><li><code>nondeterministic function</code>(like now()) is likely to generate a different value on each replica.</li><li>they must be executed in exactly the <code>same order</code> on each replica, or else they may have a different effect. This can be limiting when there are multiple concurrently executing transactions.</li><li>Statements that have <code>side effects</code>, unless the side effects are absolutely deterministic.</li></ul><p>以上问题是可以绕过的</p><h5><span id="write-ahead-logwal-shipping">Write-ahead log(WAL) shipping</span></h5><p>这是什么? 如何实现?</p><p>Describes the data on a very low level: a WAL contains details of which bytes were changed in which disk blocks。</p><p>因此难以适应数据存储格式的变化,但是可以解决 statement-based 的问题。</p><h5><span id="logicalrow-based-log-replication">Logical(row-based) log replication</span></h5><p>Logical log: 使用和 storage engine 不同的存储格式, 以便于解耦 log 和 storage engine</p><p>优点:</p><ul><li>因为解耦所以 it can more easily be kept backward compatible, allowing the leader and the follower to run different versions of the database software, or even different storage engines.</li><li>A logical log format is also easier for external applications to parse</li></ul><h5><span id="trigger-based-replication">Trigger-based replication</span></h5><p>move replication up to the application layer.</p><blockquote><p>An alternative is to use features that are available in many relational databases: <code>triggers</code> and stored procedures. </p></blockquote><blockquote><p>A trigger lets you register custom application code that is automatically executed when a data change (write transaction) occurs in a database system. The trigger has the opportunity to log this change into a separate table, from which it can be read by an external process. That external process can then apply any necessary application logic and replicate the data change to another system.<br>it can nevertheless be useful due to its flexibility.</p></blockquote><p>优点是灵活,缺点是 is more prone to bugs and limitations than the database’s built-in replication</p><h2><span id="problems-with-replication-lag">Problems with Replication Lag</span></h2><blockquote><p>Replication Lag: the delay between a write happening on the leader and being reflected on a follower</p></blockquote><blockquote><p>In this <code>read-scaling architecture(Leader-based)</code>, this approach only realistically works with asynchronous replication, <code>why?</code>: synchronously 会导致系统不可用的几率变高 so a fully synchronous configuration would be very unreliable.如果使用异步系统,又会面临数据一致性问题。</p></blockquote><p><code>所以本节主要介绍导致 lag 过长的场景和解决这些问题的方法.</code></p><h4><span id="reading-your-own-writes">Reading Your Own Writes</span></h4><blockquote><p>read-after-write consistency(read-your-writes consistency): 保证写入方写入后立即可见,但对其他 user 不进行保证</p></blockquote><p>一些解决方案:</p><ul><li><p>When reading something that the user may have modified, read it from the leader; otherwise, read it from a follower, 但是当一个用户对系统进行大量读写的话,这个方式就会变得低效</p></li><li><p>client 端可以记录 write 的时间戳,向系统请求的时候带上时间戳,系统根据时间戳来判断当前 replica 是否可以提供服务,如果不行,就尝试其他的 replica, 否则一直等待直到收到数据写入,可以服务</p></li><li><p>If your replicas are distributed across multiple datacenters (for geographical proximity to users or for availability), there is additional complexity. Any request that needs to be served by the leader must be routed to the datacenter that contains the leader.</p></li></ul><p>保证 Cross-device read-after-write consistency 的问题:</p><ol><li>remembering the timestamp of the user’s last update become more difficult</li><li>If your replicas are distributed across different datacenters,there is no guarantee that connections from different devices will be routed to the same datacenter</li></ol><h4><span id="monotonic-readsasync-情况下">Monotonic Reads(async 情况下)</span></h4><p>对于 async followers 来说,由于 lag 不同,用户可能从不同的 follower 读到不同的数据,有些是过时的。</p><p>Monotonic reads 保证不读到<code>过时</code>的数据. It’s a lesser guarantee than strong consistency, but a stronger guarantee than eventual consistency.</p><blockquote><p>If one user makes several reads in sequence, they will not see time go backward</p></blockquote><p>One way of achieving monotonic reads is to make sure that each user always makes their reads from the same replica</p><h4><span id="consistent-prefix-reads">Consistent Prefix Reads</span></h4><p>consistent prefix reads:  This guarantee says that if a sequence of writes happens in a certain order, then anyone reading those writes will see them appear in the same order.</p><p>This is a particular problem in <code>partitioned (sharded) databases</code>。in many distributed,databases, different partitions operate independently, so there is no global ordering of writes</p><p>一种解决方式事保证互相关联的写入被写入到同一个 partition.</p><h4><span id="solutions-for-replication-lag">Solutions for Replication Lag</span></h4><p>在 eventually consisten system 中 lag 不断增长怎么办?<br>provide a stronger guarantee, such as read-after-write</p><p>但是 Eventual consistency 是不够的, db 需要 <code>Transactions</code> 来提供强一致性保证。</p><h2><span id="multi-leader-replication">Multi-Leader Replication</span></h2><p>可用性高,但是会面临 write conflicts 的问题,如何解决数据一致性问题?</p><p>是什么: </p><p>Multi-leader configuration (also known as master–master or active&#x2F;active replication). In this setup, each leader simultaneously acts as a follower to the other leaders. 如 akka cluster</p><h3><span id="use-cases-for-multi-leader-replication">Use Cases for Multi-Leader Replication</span></h3><p>不适应于创建 datacenter</p><h4><span id="multi-datacenter-operation">Multi-datacenter operation</span></h4><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p16" alt="254534cc66a43b11f4f636b0cab2e63b.png"></p><p>相比于 single-leader 方案的<code>优势</code>:</p><ul><li><p>去中心化,write request 分散到各个 leader, which means the perceived performance may be better.</p></li><li><p>Tolerance of datacenter outages: 不需要重新选举 leader</p></li><li><p>Tolerance of network problems: A multi-leader configuration with <code>asynchronous</code> replication can usually tolerate network problems better: a temporary network interruption does not prevent writes being processed</p></li></ul><p>缺点: the same data may be concurrently modified in two different datacenters, and those <code>write conflicts</code> must be resolved </p><p>一些使用 multi-leader 的系统:</p><ul><li>Tungsten Replicator for MySQL</li><li>BDR for PostgreSQL</li><li>GoldenGate for Oracle</li></ul><h4><span id="clients-with-offline-operation">Clients with offline operation</span></h4><p>if you have an application that needs to continue to work while it is disconnected from the internet. 怎么解决？</p><p>比如在多个设备上使用同一个app, every device has a local database that acts as a leader (it accepts write requests), and there is an asynchronous multi-leader replication process (sync) between the replicas of your app on all of your devices</p><p>CouchDB is designed for this mode of operation</p><h4><span id="collaborative-editing">Collaborative editing</span></h4><p>Real-time collaborative editing applications allow several people to edit a document simultaneously</p><p>会有啥问题? 怎么解决?</p><p>如果加锁的话就 is equivalent to single-leader replication with transactions on the leader.</p><p>如果想避免枷锁,就会带来 challenges of multi-leader replication, including requiring conflict resolution </p><h3><span id="handling-write-conflicts">Handling Write Conflicts</span></h3><p>The biggest problem with multi-leader replication is that <code>write conflicts</code> can occur. 比如对同一份数据的修改请求到不同的 leader.</p><p>在 Multi-leader 情况下,只能异步的进行冲突检测,it may be too late to ask the user to resolve the conflict.</p><h4><span id="conflict-avoidance">Conflict avoidance</span></h4><p>avoid them: if the application can ensure that all writes for a particular record go through the same leader, then conflicts cannot occur.</p><h4><span id="converging-toward-a-consistent-state">Converging toward a consistent state</span></h4><p>In a multi-leader configuration, there is <code>no defined ordering of writes</code>, so it’s not clear what the final value should be. 所以 all replicas must arrive at the same final value when all changes have been replicated.</p><p>4 种常用解决 write conflict 的方法:</p><ul><li>Give <code>each write a unique ID</code>,比如 <code>last write wins方式</code>:冲突时,选择最新的一条,但是这会有丢数据的风险</li><li>Give <code>each replica a unique ID</code>,ID越高则其对应的数据也有更高优先级，不过也意味着某些数据的无条件丢失。</li><li>合并：将冲突的值排序并连接起来, 如“你很漂亮&#x2F;帅”</li><li>Record the conflict in an explicit data structure that preserves all information, and write application code that <code>resolves the conflict at some later time</code></li></ul><h4><span id="custom-conflict-resolution-logic">Custom conflict resolution logic</span></h4><p>用户编写冲突处理逻辑, That code may be executed on write or on read:</p><p>On write: 修改数据时若检测到了冲突，则立即调用conflict handler处理。</p><p>On read: 存储所有有冲突的写入,读取时给出所有版本数据,用户自己进行数据选择。</p><blockquote><p>Note that conflict resolution usually applies at the level of an individual row or document, not for an entire transaction</p></blockquote><blockquote><p><code>Automatic conflict resolution</code> could make multi-leader data synchronization much simpler for applications to deal with.</p></blockquote><h3><span id="multi-leader-replication-topologies">Multi-Leader Replication Topologies</span></h3><p><code>各个拓扑的介绍和优缺点?</code></p><blockquote><p>replication topology: 如图,描述 writes request 在所有 nodes 间的传递轨迹。</p></blockquote><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p17" alt="7e3188d1f6c822d488f4f5241f7807e0.png"></p><p>Circular 和 star 的问题在于如果有 node down 掉, it can interrupt the flow of replication messages between other nodes. all-to-all 可以通过其他传递路径来避免这个问题.</p><p>all-to-all 缺点: 网络速度差异会导致 the result that some replication messages may “overtake” others</p><h2><span id="leaderless-replication">Leaderless Replication</span></h2><p>Allowing any replica to directly accept writes from clients. 写的时候发送 write 到多个 replica, 多数成功则成功。读的时候也从多个 replica 读取,通过版本对比采纳最新的那份数据。</p><blockquote><p>In some leaderless implementations, the client directly sends its writes to several replicas, while in others, a <code>coordinator node does this on behalf of the client</code>. However, unlike a leader database, that coordinator does not enforce a particular ordering of writes</p></blockquote><blockquote><p>Leaderless replication is also suitable for multi-datacenter operation, since it is designed to <code>tolerate conflicting concurrent writes</code>, <code>network interruptions</code>, and <code>latency spikes</code>.</p></blockquote><h3><span id="writing-to-the-database-when-a-node-is-down">Writing to the Database When a Node Is Down</span></h3><p>不存在 failover, client 直接忽略写失败的 replica, 写会同步请求多个 node,Version numbers are used to determine which value is newer</p><h4><span id="read-repair-and-anti-entropy">Read repair and anti-entropy</span></h4><p>当 down 掉的机器恢复后,如何恢复缺失的数据呢,有 2 种常用方式:</p><ul><li><p>Read repair: 读取的时候检测 stale value 并 recover, This approach works well for values that are frequently read.</p></li><li><p>Anti-entropy process: some datastores have a background process that constantly looks for differences in the data between replicas and copies any missing data from one replica to another</p></li></ul><p><code>没有顺序如何保证写入的因果关系?</code></p><h4><span id="quorums-for-reading-and-writing">Quorums for reading and writing</span></h4><p>设想:<br>n: replica 数量<br>w: 每个 write 都要保证 w 个节点写成功<br>r: 读取的时候至少从 r 个节点读取数据<br>所以只要 w + r &gt; n, 这样读取的时候一定会读取到 w 中至少一个节点的数据,所以可以读到最新的数据。</p><p>A common choice is to make n an odd number (typically 3 or 5) and to set w &#x3D; r &#x3D; (n + 1) &#x2F; 2 (rounded up). 可概以根据应用的读写情况对参数做调整.</p><p>The quorum condition, w + r &gt; n, allows the system to tolerate unavailable nodes as follows:</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p19" alt="80e62fa44d8d83fbea8d5ebe8e260653.png"></p><h4><span id="limitations-of-quorum-consistency">Limitations of Quorum Consistency</span></h4><p>即使 w + r &gt; n, 也是无法完全保证数据强一致性的.<br>Stronger guarantees generally require <code>transactions</code> or consensus.</p><h4><span id="sloppy-quorums-and-hinted-handoff草率的对话和暗示的交接">Sloppy Quorums and Hinted Handoff(草率的对话和暗示的交接)</span></h4><p>leader-less dababase 可以提供 high availability and low latency, and that can tolerate occasional stale reads. </p><p>有些 quorums 并不能提供良好的 fault-toleratn,比如当发生网络split 时,一些 client 会离开集群,一些新的 client 可能会加入集群.此时如果保证 w 写入,但是 read 可能会读取到新加入的 client,从而无法拿到最新的数据.</p><h2><span id="detecting-concurrent-writes">Detecting Concurrent Writes</span></h2><p>The problem is that events may arrive in a different order at different nodes, due to variable network delays and partial failures</p><p>当数据对写入顺序有要求(如聊微信)时,如何保证 eventually consisteny</p><h4><span id="last-write-winsdiscarding-concurrent-writes">Last write wins(discarding concurrent writes)</span></h4><p>可以在多个冲突的写入中间选取最难 <code>recent</code> 的那个,如 LWW,其他的写入则被丢弃</p><blockquote><p>The only safe way of using a database with LWW is to ensure that a key is only written once and thereafter treated as immutable, thus avoiding any concurrent updates to the same key.</p></blockquote><h4><span id="capturing-the-happens-before-relationship">Capturing the happens-before relationship</span></h4><p>可以在 write request 中加入版本号,server 通过版本号来确定 2 个操作是不是并发(2个操作没有依赖关系)执行。</p><p>When a write includes the version number from a prior read, that tells us which previous state the write is based on.</p><h4><span id="merging-concurrently-written-values">Merging concurrently written values</span></h4><p>As merging siblings in application code is complex and error-prone, there are some efforts to design data structures that can perform this merging <code>automatically</code>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2&gt;&lt;span id&gt;?&lt;/span&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Replication 和 partition 如何组合使用?&lt;/li&gt;
&lt;li&gt;如何解决&lt;code&gt;并发&lt;/code&gt;问题?&lt;/li&gt;
&lt;li&gt;如何保证 &lt;code&gt;consistency&lt;/code&gt;?&lt;/</summary>
      
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="ddia" scheme="http://example.com/tags/ddia/"/>
    
  </entry>
  
  <entry>
    <title>Part 1: CHAPTER 4 Encoding and Evolution</title>
    <link href="http://example.com/2019/09/15/Part-1-CHAPTER-4-Encoding-and-Evolution/"/>
    <id>http://example.com/2019/09/15/Part-1-CHAPTER-4-Encoding-and-Evolution/</id>
    <published>2019-09-15T06:21:45.000Z</published>
    <updated>2022-11-25T06:24:25.091Z</updated>
    
    <content type="html"><![CDATA[<h2><span id>?</span></h2><ul><li>Encoding 的含义是什么? 如何实现?</li><li>Encoding 需要注意什么? 兼容性</li><li>Encoding 的现状和发展趋势是什么?</li><li>如何保持 forward compatibility?</li><li>Protocol Buffers, Thrift, and Avro 都是什么?</li><li>REST, RPC, Actors, message queue 各自的概念和区别以及应用场景?</li><li>RPC 相比于 REST 的优势在哪? 主要应用场景是什么?</li><li>evolution of schemas over time?</li></ul><h2><span id="summary">Summary</span></h2><blockquote><p>data outlives code</p></blockquote><ol><li><p>本文介绍了多种 encoding(<code>turning data structures into bytes on the network or bytes on disk</code>) 方式,并介绍了它们的实现细节和效率。</p><p> 涉及到 3 种 encoding formats:5 </p><ul><li>Programming language–specific: 被语言限制并且对兼容性支持不好</li><li>Textual formats: JSON, XML, and CSV: (1)兼容性取决于使用方式 (2)These formats are somewhat vague about datatypes</li><li>Binary schema–driven formats: Thrift, Protocol Buffers, Avro</li></ul></li><li><p>由于分布式环境下 many services need to support rolling upgrades, 所以 encoding 需要支持向前和向后兼容</p></li><li><p>encoding 的重要使用场景:</p><ul><li>Databases: 写入时 encode, 读取时 decode </li><li>RPC and REST APIs: client encodes a request, the server decodes the request and encodes a response, and the client finally decodes the response</li><li>Asynchronous message passing: encoded by the sender and decoded by the recipient</li></ul></li></ol><h2><span id="use">use</span></h2><p>we must assume that different nodes are running the different versions of our application’s code.</p><h2><span id="formats-for-encoding-data">Formats for Encoding Data</span></h2><p>使用特定语言的序列化和反序列化类库存在跨语言,兼容性,安全性,性能等诸多问题,不建议使用。所以着重介绍 binary encoding。</p><h3><span id="json-xml-csv-are-textual-formats">JSON, XML, CSV are textual formats</span></h3><p>适合作为数据交换 format, JSON,XML,CSV 的问题:</p><ul><li>There is a lot of <code>ambiguity</code> around the encoding of numbers</li><li>don’t support binary strings</li><li>There is optional schema support for both XML and JSON,and thus quite complicated to learn and implement</li><li>CSV does not have any schema</li></ul><h3><span id="binary-encoding">Binary encoding</span></h3><p>在大数据量下使用 textual formats(更具可读性) 太过耗费空间,所以需要 binary encoding。</p><p>Some of these formats extend the set of datatypes, they need to include all the object field names within the encoded data.</p><h4><span id="thrift-and-protocol-buffers">Thrift and Protocol Buffers</span></h4><p>2 者都 based on the same principle,即: </p><ol><li><p>需要定义数据的 schema, 字段可以被标示为 optional 或者 required, 可以在 runtime 时对字段合法性进行 check, 同时使用 field tag 而非 field name 来压缩数据。</p></li><li><p>每条数据中包含 schema 信息,参见下图 <code>Protocol Buffers</code></p></li></ol><blockquote><p>Thrift(<code>not good fit for Hadoop</code>) 有 2 种编码方式: BinaryProtocol 和 CompactProtocol</p></blockquote><p><img src="https://martin.kleppmann.com/2012/12/protobuf.png" alt="Protocol Buffers"></p><h5><span id="field-tags-and-schema-evolution">Field tags and schema evolution</span></h5><p>How do Thrift and Protocol Buffers handle schema changes while keeping backward and forward compatibility?</p><p>Forward compatibility: 添加了新字段后,老的代码读取数据的时候忽略新的字段即可</p><p>Backward compatibility: As long as each field has a unique tag number, new code can always read old data</p><p>Removing a field is just like adding a field, with backward and forward compatibility concerns reversed.</p><h5><span id="datatypes-and-schema-evolution">Datatypes and schema evolution</span></h5><p>数据类型改变时, 只能部分的支持兼容性。<br>数据类型改变时, there is a risk that values will <code>lose precision</code> or <code>get truncated</code></p><p>Thrift 有 list 类型,不支持 single 和 list 的相互转换</p><p>protocol buffer 没有 list 类型,list 是 mutiple single, 所以可以支持 single 和 list 间的转换</p><h4><span id="avro-hadoop-的子项目">Avro: hadoop 的子项目</span></h4><p>Avro also uses a schema to specify the structure of the data being encoded.</p><p>encoding 数据中不包含 schema 信息,读取的时候 you go through the fields in the order that they appear in the schema and use the schema to tell you the datatype of each field.</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p25" alt="bf15fdd316edbb8d122d88d23f3ead6c.png"></p><h5><span id="the-writers-schema-and-the-readers-schema">The writer’s schema and the reader’s schema</span></h5><blockquote><p><code>Writer&#39;s schema:</code> encodes the data using whatever version of the schema it knows about<br><code>Reader’s schema:</code> it is expecting the data to be in some schema</p></blockquote><p>那怎么保证 shcema 变更导致的兼容性?</p><p>The key idea with Avro is that the writer’s schema and the reader’s schema don’t have to be the same—they only need to be compatible</p><h5><span id="schema-evolution-rules">Schema evolution rules</span></h5><p>To maintain compatibility, you may only add or remove a field that <code>has a default value</code></p><p>Avro doesn’t have optional and required markers in the same way as Protocol Buffers and Thrift do.</p><p>Changing the datatype of a field is possible, provided that Avro can convert the type.</p><h5><span id="but-whats-the-writers-schema">But whats the writers schema</span></h5><p>how does the reader know the writer’s schema with which a particular piece of data was encoded?</p><ol><li><p>the writer of that file can just include the writer’s schema once at the beginning of the file</p></li><li><p>The simplest solution is to include a version number at the beginning of every encoded record, and to keep a list of schema versions in your database (类似 es)</p></li><li><p>网络通信时: they can negotiate the schema version on connection setup and then use that schema for the lifetime of the connection.</p></li></ol><h5><span id="dynamically-generated-schemas">Dynamically generated schemas</span></h5><p>Avro schema 中不包含 tag number, 所以 Avro is friendlier to dynamically generated schemas.</p><p>This kind of dynamically generated schema simply wasn’t a design goal of Thrift or Protocol Buffers, whereas it was for Avro.</p><h3><span id="modes-of-dataflow">Modes of Dataflow</span></h3><p>There are many ways data can flow from one process to another, 看看 encoding 在其中的价值:</p><ul><li>Via databases</li><li>Via service calls</li><li>Via asynchronous message passing</li></ul><h4><span id="dataflow-through-databases">Dataflow Through Databases</span></h4><p>关系型中的数据写入时间差异很大,所以向前向后兼容都需要。</p><h4><span id="dataflow-through-services-rest-and-rpc">Dataflow Through Services: REST and RPC</span></h4><p>SOA(microservices): This approach is often used to decompose a large application into smaller services by area of functionality.</p><p>In other words, we should expect old and new versions of servers and clients to be running at the same time, and so the data encoding used by servers and clients must be compatible across versions of the service API precisely what we’ve been talking about in this chapter.</p><h5><span id="web-services">Web services</span></h5><p><code>REST:</code> is not a protocol, but rather a design philosophy that builds upon the principles of HTTP. It emphasizes simple data formats, using URLs for identifying resources and using HTTP features for cache control, authentication, and content type negotiation.</p><p><code>SOAP:</code> is an XML-based protocol for making network API requests. Although it is most commonly used over HTTP, it aims to be independent from HTTP and avoids using most HTTP features. </p><blockquote><p>SOAP 的例子:<a href="https://www.cnblogs.com/mfrbuaa/p/3986739.html">https://www.cnblogs.com/mfrbuaa/p/3986739.html</a></p></blockquote><h5><span id="the-problems-with-remote-procedure-callsrpcs">The problems with remote procedure calls(RPCs)</span></h5><p>Although RPC seems convenient at first, the approach is fundamentally flawed:</p><ol><li>网络问题不可控,必须自己做容错</li><li>if you don’t get a response from the remote service, you have no way of knowing whether the request got through or not.</li><li>需要 deduplication 机制</li><li>A network request is much slower than a function call, and its latency is also wildly variable</li><li>序列化和反序列化</li><li>不同语言之间的类型转换可能导致问题</li></ol><p>Thus, you only need backward compatibility on requests, and forward compatibility on responses.</p><h4><span id="message-passing-dataflow如-akka">Message-Passing Dataflow(如: Akka)</span></h4><p>A client’s request (usually called a message) is delivered to another process with low latency. message is not sent via a direct network connection, but goes via an intermediary called a message broker (also called a message queue or message-oriented middleware), which stores the message temporarily.</p><p>A sender normally doesn’t expect to receive a reply to its messages. This communication pattern is asynchronous: the sender doesn’t wait for the message to be delivered, but simply sends it and then forgets about it.</p><h5><span id="message-brokers">Message brokers</span></h5><p>produecers -&gt; topic -&gt; consumers<br>Message brokers typically don’t enforce any particular data model</p><h5><span id="distributed-actor-frameworks">Distributed actor frameworks</span></h5><p>Location transparency works better in the actor model than in RPC, because the actor model already assumes that messages may be lost.</p><p>Akka uses Java’s built-in serialization by default, which does not provide forward or backward compatibility</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2&gt;&lt;span id&gt;?&lt;/span&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Encoding 的含义是什么? 如何实现?&lt;/li&gt;
&lt;li&gt;Encoding 需要注意什么? 兼容性&lt;/li&gt;
&lt;li&gt;Encoding 的现状和发展趋势是什么?&lt;/li&gt;
&lt;li&gt;如何保持 forward</summary>
      
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="ddia" scheme="http://example.com/tags/ddia/"/>
    
  </entry>
  
  <entry>
    <title>Part 1: CHAPTER 3 Storage and Retrieval</title>
    <link href="http://example.com/2019/09/14/Part-1-CHAPTER-3-Storage-and-Retrieval/"/>
    <id>http://example.com/2019/09/14/Part-1-CHAPTER-3-Storage-and-Retrieval/</id>
    <published>2019-09-14T06:19:32.000Z</published>
    <updated>2022-11-25T06:26:13.604Z</updated>
    
    <content type="html"><![CDATA[<h2><span id>?</span></h2><ol start="0"><li>how databases arrange data on disk so that we can find it again efficiently?</li><li>how we can store the data that we’re given(如何存储数据)?</li><li>how we can find it again when we’re asked for it(如何检索数据)?</li><li>storage engine optimized for transactional(<code>OLTP</code>) 和 optimized for analytics(<code>OLAP</code>) 有何不同?</li><li>log-structured storage engines(如 <code>LSM-Trees</code>) and page-oriented storage enginers(如 <code>B-Trees</code>)?</li><li>index 的类型和原理?</li><li>内存中的结构是什么样, 磁盘的结构又是什么样? 如何从内存刷到磁盘, 又从磁盘恢复到内存?</li><li>data model, index, column-oriented, encoding 之间是如何配合的,它们之间的关系是什么</li></ol><h2><span id="oltponline-transaction-processing-overview">OLTP(online transaction processing) Overview</span></h2><blockquote><p>A transaction needn’t necessarily have ACID (atomicity, consistency, isolation, and durability) properties. Transaction processing just means allowing clients to make low-latency reads and writes as opposed to batch processing jobs, which only run periodically (for example, once per day). </p></blockquote><p><code>Storage:</code> 相比随机写入顺序写入简单高效, 因此 Many databases internally use a log(an append-only sequence of records), which is an <code>append-only</code>(the simplest possible write operation) data file.</p><p><code>Retrieval:</code> TP 应用通常面向用户,使用 key 检索数据,结果集也通常较小,对响应时间有要求,因此 store engine 使用 index 来加速查询。Disk seek time is often the bottleneck here.</p><blockquote><p><code>Index:</code> Index 利用额外的存储(来自 data)来加速查询. 维持 index 会面临一些成本,尤其是当写入时,需要同步更新 index。由于 index 可以加速查询, 降低写入效率,所以索引的建立需开发人员去权衡.</p></blockquote><h3><span id="hash-indexes-with-append-only">Hash Indexes with append-only</span></h3><p><code>Storage:</code> 数据以 (k,v) pair 的形式存储在磁盘,以 append only 的方式进行追加<br><code>Retrieval:</code> 在内存中维护 hash index,数据追加时同步更新 index</p><p><img src="https://notes.shichao.io/dda/figure_3-1.png" alt="image"></p><p><strong>以 append-only 方式追加会导致磁盘空间不足,为了解决这个问题:</strong></p><ol><li>将 log 切分为定长的 segment, 当 segment file 到达固定大小时,后续的 log 写入新的 segment file</li><li>定期对 segment file 进行 compaction(throwing away duplicate keys in the log, and keeping only the most recent update for each key),也可以将多个 segment file compaction 为一个</li><li>segment file 是只读的, compaction 会产生新的文件.在 compaction 的同时, old segment file 仍可以提供读写服务.当 compaction 完成时,使用新的 segment file, 删除老的 segment file。</li></ol><p><strong>这个方案一些要关注的点:</strong></p><ul><li>File format: use a binary format that first encodes the length of a string in bytes, followed by the raw string</li><li>Deleting records: use a binary format that first encodes the length of a string in bytes, followed by the raw string. merge 的时候会删除数据.</li><li><code>Crash recovery</code>: Bitcask speeds up recovery by storing a snapshot of each segment’s hash map on disk, which can be loaded into memory more quickly.</li><li><code>Partially written records</code>: include checksums, allowing such corrupted parts of the log to be detected and ignored.</li><li><code>Concurrency control</code>: 单线程写入,一个 file 要么是 append-only 要么是 immutable, 所以可以多线程读取</li></ul><p><strong>优势:</strong></p><ul><li>append 和 segment merge 是顺序写入操作,比随机写入要高效</li><li>Concurrency and crash recovery are much simpler if segment files are append-only or immutable</li><li>Merging old segments avoids the problem of data files getting fragmented over time.</li></ul><p><strong>Limitations:</strong></p><ul><li>The hash table must fit in memory,当 hash table 很<br>大被迫放入磁盘时,索引效率就会下降,还会面临 hash 冲突的问题.</li><li>Range queries are not efficient.</li></ul><h3><span id="sstablessorted-string-table-and-lsm-trees">SSTables(Sorted String Table) and LSM-Trees</span></h3><blockquote><p><a href="https://www.open-open.com/lib/view/open1424916275249.html">https://www.open-open.com/lib/view/open1424916275249.html</a><br><a href="https://ggaaooppeenngg.github.io/zh-CN/2017/03/31/%E4%BB%8E%E6%9C%B4%E7%B4%A0%E8%A7%A3%E9%87%8A%E5%87%BA%E5%8F%91%E8%A7%A3%E9%87%8Aleveldb%E7%9A%84%E8%AE%BE%E8%AE%A1/">https://ggaaooppeenngg.github.io/zh-CN/2017/03/31/%E4%BB%8E%E6%9C%B4%E7%B4%A0%E8%A7%A3%E9%87%8A%E5%87%BA%E5%8F%91%E8%A7%A3%E9%87%8Aleveldb%E7%9A%84%E8%AE%BE%E8%AE%A1/</a></p></blockquote><p>如何使用 SSTables 来解决 hash index 的问题呢</p><p><code>Storage:</code> 在 hash index 中 k,v 数据按照写入顺序存储,且同一个 k 会存在多个 segment file 中。在 SSTable 中, we require that the sequence of key-value pairs is <code>sorted by key</code>.We also require that each key <code>only appears once </code> within each merged segment file</p><p><code>Retrieval:</code> 因为 key 按序存储,所以 index 中的一个 key 可以表示一个范围的上&#x2F;下界,找到数据所在范围后再 scan 者个范围内的数据。先检索内存中的 memtable, 再根据时间检索磁盘上的 SSTables.</p><p><img src="https://miro.medium.com/max/4000/0*6zJnBf20REcr4Uet.png" alt="img"></p><p><strong>Advantages:</strong></p><ul><li>Merging segments is simple and efficient, even if the files are bigger than the available memory, 类似于合并有序数组</li><li>you no longer need to keep an index of all the keys in memory. 因为有序, hash table 中的一个 key 可以代表一个范围的上&#x2F;下界,通过 scan 这个小范围来检索数据</li><li>it is possible to <code>group those records into a block and compress it</code> before writing it to disk. 这可以节省磁盘同时也能降低 IO 带宽</li></ul><h5><span id="constructing-and-maintaining-sstables">Constructing and maintaining SSTables</span></h5><p>Sorted structure on disk: LSM-tree(Log-Structured Merge-Tree)?<br>Sorted structure in memory: red-black trees or AVL trees</p><p><strong>Work flow:</strong></p><ol><li>add write to and in-memory balanced tree structure called <code>memtable</code></li><li>When the memtable gets bigger than some threshold—typically a few megabytes—write it out to <code>disk as an SSTable file</code>.</li><li>In order to serve a read request, first try to find the key in the memtable, then in the most recent on-disk segment, then in the next-older segment, etc.</li><li>From time to time, run a merging and compaction process in the background to combine segment files and to discard overwritten or deleted values.</li></ol><p><code>唯一的问题:</code> 当 database crashed, 还没刷到磁盘的 memetable 就会丢失,为了避免这个问题,写一条数据时,同时以简单的 append 方式追加到一个 log 中,便于 crash 后 memtable 的恢复</p><h5><span id="lsm-treelog-structured-merge-tree">LSM-tree(Log-Structured Merge-Tree)</span></h5><p><code>写快读慢,因为顺序写入,读取的时候需要检索 memtable 和 sstable.</code></p><p>Storage engines that are based on this principle of merging and compacting sorted files are often called LSM storage engines.</p><p>the basic idea of LSM-trees—keeping a cascade of SSTables that are merged in the background is simple and effective</p><p>由于数据存储有序,所以 index 可以进行 range query,这保证了再大数据集下不错的检索性能。<br>由于顺序写入, LSM-tree 也可以支持大的写吞吐;</p><p>Reads are typically slower on LSM-trees because they have to check several different data structures and SSTables at different stages of compaction.</p><h4><span id="performance-optimizations">Performance optimizations</span></h4><ul><li>检索一个不存在的 key 费时费力,为了解决这个问题,常使用额外的 bloom-filter</li></ul><p><strong>Merge 和 compact 方式:</strong></p><ul><li><p>size-tiered: newer and smaller SSTables are successively merged into older and larger SSTables.</p></li><li><p>leveled compaction: the key range is split up into smaller SSTables and older data is moved into separate “levels,” which allows the compaction to proceed more incrementally and use less disk space</p></li></ul><h3><span id="b-trees">B-Trees</span></h3><p><code>Storage:</code> (k,v) 按 k 有序存储,which allows efficient key-value lookups and range queries。B-trees break the database down into <code>fixed-size blocks or pages</code>, traditionally 4 KB in size (sometimes bigger), and read or write one page at a time. This design corresponds more closely to the underlying hardware, as disks are also arranged in fixed-size blocks.</p><blockquote><p>Most databases can fit into a B-tree that is three or four levels deep, so you don’t need to follow many page references to find the page you are look‐ing for. (A four-level tree of 4 KB pages with a branching factor of 500 can store up to 256 TB.)</p></blockquote><h5><span id="making-b-trees-reliable">Making B-trees reliable</span></h5><p>B-tree is to overwrite a page on disk with new data. It is assumed that the overwrite does not change the location of the page;</p><ul><li><p><strong>fault-tolerant when database crash?</strong><br>In order to make the database resilient to crashes, it is common for B-tree implementations to include an additional data structure on disk: a <code>write-ahead log</code> (WAL, also known as a redo log).</p></li><li><p><code>并发问题:</code> This is typically done by protecting the tree’s data structures with latches (lightweight locks).</p></li></ul><h5><span id="b-tree-optimizations">B-tree optimizations</span></h5><ul><li>copy-on-write</li><li>……</li></ul><h3><span id="comparing-b-trees-and-lsm-trees">Comparing B-Trees and LSM-Trees</span></h3><p>B-tree: 写慢读快;每条数据只存在于一个地方,所以可以支持强大的事务能力<br>Lsm-tree: 写快读慢,同一个 key 可能在不同的 segment 中</p><h4><span id="advantages-of-lsm-trees">Advantages of LSM-trees</span></h4><p><code>相比于 B-trees, LSM-trees 可以维持 higher write throughput:</code></p><ol><li>lsm-trees have lower write amplification</li><li>sequentially write compact SSTable</li></ol><p><code>LSM-trees 磁盘利用率相对较高</code>: LSM-trees can be compressed better, and thus often produce smaller files on disk than B-trees.</p><blockquote><p>write amplification(写放大):</p><ul><li>A B-tree index must write every piece of data at least twice: index 和 数据</li><li>Log-structured indexes also rewrite data multiple times due to repeated compaction and merging of SSTables</li></ul></blockquote><h4><span id="downsides-of-lsm-trees写入时空间换时间">Downsides of LSM-trees:写入时空间换时间</span></h4><ol><li><p>compaction process 有时和 ongoing reads and writes process 会互相干扰</p></li><li><p>Another issue with compaction arises at high write throughput: the disk’s finite write bandwidth needs to be shared between the initial write (logging and flushing a memtable to disk) and the compaction threads running in the background.</p></li></ol><h3><span id="other-indexing-structures">Other Indexing Structures</span></h3><p>二级索引</p><h4><span id="storing-values-within-the-index">Storing values within the index</span></h4><p>数据存储在 heap file 中,索引处存储 heap file 的 reference,这样可以避免重复存储数据.index 中新值可以 overwrite 老值, index 无需更新; 如果空间不够需要生成新的 heapfile, 则需要更新 index。</p><p><code>clustered index(storing all row data within the index):</code> so it can be desirable to store the indexed row directly within an index. This is known as a clustered index(<code>聚集索引,比如 mysql 主键</code>).</p><p><code>covering index:(比如 mysql 主键外其他键上索引)</code> which stores some of a table’s columns within the index </p><h4><span id="multi-column-indexes">Multi-column indexes</span></h4><p><code>concatenated index(比如 mysql 联合唯一键):</code> simply combines several fields into one key by appending one column to another (the index definition specifies in which order the fields are concatenated)</p><p>Multi-dimensional indexes are a more general way of querying several columns at once, 比如 R 树?</p><h4><span id="full-text-search-and-fuzzy-indexes">Full-text search and fuzzy indexes</span></h4><p>To cope with typos in documents or queries, Lucene is able to search text for words within a certain edit distance</p><p>but in Lucene, the in-memory index is a finite state automaton over the characters in the keys, similar to a trie </p><h4><span id="keeping-everything-in-memory">Keeping everything in memory</span></h4><p>But other in-memory databases aim for durability, which can be achieved with special hardware (such as battery-powered RAM), by writing a log of changes to disk, by writing periodic snapshots to disk, or by replicating the in-memory state to other machines.</p><p><strong>Counterintuitively, the performance advantage of in-memory databases is not due to the fact that they don’t need to read from disk.Rather, they can be faster because they can avoid the overheads of encoding in-memory data structures in a form that can be written to disk</strong></p><p>Besides performance, another interesting area for in-memory databases is providing data models that are difficult to implement with disk-based indexes. </p><h3><span id="summary">Summary</span></h3><h4><span id="log-structured-storage-engine">Log-structured storage engine</span></h4><p>Hash Index + append only</p><ul><li>log 分为 segments, 后台 merge 和 compaction, 磁盘利用率低</li><li>index 受内存大小限制</li><li>难以进行 range query</li></ul><p>Range Index + SSTable(LSM-Trees 是其进阶)</p><ul><li>写入按 k 排序, 写入 mmtable(memory), 写满后刷到 SSTable(disk)</li><li>range index + scan filter, 不受内存限制, range query 支持良好</li><li>后台进行 merge(高效的有序合并) 和 compaction; 磁盘利用率高</li><li>相对读慢写快(顺序写入,append-only,不 update,合并时 delete)</li><li>crash recovery: append-only log</li><li>并发问题: 以上 2 个都是单线程写入, segment file 不可变,可以多线程读取;</li></ul><p>Their key idea is that they systematically <code>turn random-access writes into sequential writes on disk</code>, which enables higher write throughput due to the performance characteristics of hard drives and SSDs.</p><h4><span id="page-orientated-storage-engine">Page-orientated storage engine</span></h4><p>B-Trees(update-in-place)</p><ul><li>按 k 排序,会进行 update(overwrite)</li><li>数据只有一份,事务支持强大</li><li>读快写慢(随机写入,还有可能 B 树要分裂)</li><li>crash recovery: write-ahead log</li><li>concurrency issue: latches (lightweight locks)</li><li>二级索引,聚集索引,非聚集索引…</li><li>Multi-column indexes</li></ul><h4><span id="else">else</span></h4><ul><li>全文索引</li><li>模糊索引</li><li>Keeping everything in memory</li></ul><h2><span id="olaponline-analytic-processing-overview">OLAP(online analytic processing ) Overview</span></h2><p>特点: scan 大量的数据, project 一些字段,在这些数据上进行聚合运算</p><p>Instead it becomes important to encode data very compactly, <code>to minimize the amount of data that the query needs to read from disk.</code> We discussed how column-oriented storage helps achieve this goal.</p><h3><span id="data-warehousing">Data Warehousing</span></h3><p>通过 ETL 将 TP 系统中的数据以合适的方式收集到 data warehouse 中进行 AP 分析.DW 通常是关系模型,因此使用 sql 分析非常合适。</p><blockquote><p>A data warehouse, by contrast, is a separate database that analysts can query to their hearts’ content, without affecting OLTP operations</p></blockquote><p>A big advantage of using a separate data warehouse, rather than querying OLTP systems directly for analytics, is that the data warehouse can be optimized for analytic access patterns.</p><p><img src="https://panoply.io/uploads/versions/diagram4---x----750-328x---.jpg" alt="img"></p><h3><span id="stars-and-snowflakes-schemas-for-analytics">Stars and Snowflakes: Schemas for Analytics</span></h3><p><code>Stars schema(也称维度建模):</code> 中间是事实表,其通常包含很多字段,有些是属性,有些事指向维度表的外键。</p><p><img src="https://i.ytimg.com/vi/KUwOcip7Zzc/maxresdefault.jpg" alt="img"></p><p><code>Snowflakes schema:</code> 是 Stars 的变体,维度表维度和以被细分为更小的维度</p><p><img src="https://www.tutorialspoint.com/dwh/images/snowflake.jpg" alt="img"></p><blockquote><p>fact table(事实表): Each row of the fact table represents an event that occurred at a particular time<br>dimension table(维度表): the dimensions represent the who, what, where, when, how, and why of the event</p></blockquote><h3><span id="column-oriented-storage">Column-Oriented Storage</span></h3><p>row-oriented storage 对事务支持更好, column-oriented storage 对分析支持更好.</p><p>The idea behind column-oriented storage is simple: don’t store all the values from one row together, but store all the values from each column together instead.</p><p>The column-oriented storage layout relies on each column file containing the rows in the same order.</p><h3><span id="column-compression">Column Compression</span></h3><p>we can further reduce the demands on disk throughput by compressing data</p><blockquote><p>bitmap encoding<br>vectorized processing </p></blockquote><p>A big bottleneck is the bandwidth for getting data from disk into memory</p><p>Developers of analytical databases also worry about efficiently using the bandwidth from main memory into the CPU cache</p><h3><span id="sort-order-in-column-storage">Sort Order in Column Storage</span></h3><p>在列存中顺序无关紧要,存储按照 insert 顺序来就好了.但是仍然可以类似 SSTable 指定顺序用来实现索引</p><p>Rather, the data needs to be sorted an entire row at a time, even though it is stored by column.</p><p>A second column can determine the sort order of any rows that have the same value in the first column. </p><p>Another advantage of sorted order is that it can help with compression of columns</p><p><code>Having multiple sort orders in a column-oriented store is a bit similar to having mul‐ tiple secondary indexes in a row-oriented store.</code></p><h3><span id="writing-to-column-oriented-storage">Writing to Column-Oriented Storage</span></h3><p>面向列,压缩和排序增加了写入成本。可以使用类似 LSM-trees 的方式,将数据写入 memtable 再刷到磁盘,刷到磁盘的时候生成 column-oriented 文件。只是这样以来,查询就需要合并 memtable 和磁盘文件,但是查询优化器会对用户屏蔽这些底层细节。</p><h3><span id="aggregation-data-cubes-and-materialized-views">Aggregation: Data Cubes and Materialized Views</span></h3><p><code>Materialized view:</code> is and actual copy of the query results, written to disk,When the underlying data changes, a materialized view needs to be updated</p><p>A common special case of a materialized view is known as a data cube or OLAP cube, It is a grid of aggregates grouped by different dimensions.</p><p>The disadvantage is that a data cube doesn’t have the same flexibility as querying the raw data</p><p><img src="evernotecid://30F90D4C-92AC-4B27-B972-0040A5A63D68/appyinxiangcom/26101857/ENResource/p9" alt="facfdccc444fa2a500ba5c3791022f35.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2&gt;&lt;span id&gt;?&lt;/span&gt;&lt;/h2&gt;&lt;ol start=&quot;0&quot;&gt;
&lt;li&gt;how databases arrange data on disk so that we can find it again efficiently?&lt;/li&gt;
&lt;li&gt;how we ca</summary>
      
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="ddia" scheme="http://example.com/tags/ddia/"/>
    
  </entry>
  
  <entry>
    <title>Part 1: CHAPTER 2 Data Models and Query Languages</title>
    <link href="http://example.com/2019/09/08/Part-1-CHAPTER-2-Data-Models-and-Query-Languages/"/>
    <id>http://example.com/2019/09/08/Part-1-CHAPTER-2-Data-Models-and-Query-Languages/</id>
    <published>2019-09-08T05:58:07.000Z</published>
    <updated>2022-11-25T06:26:45.205Z</updated>
    
    <content type="html"><![CDATA[<h2><span id>?</span></h2><ul><li>有哪些 data model? 它们之间的区别和联系是什么? 各自解决了什么场景下的问题? 如何融合?</li><li>每个 data model 对应的 query language 是什么? 有什么特点?</li><li>关系型和文档型之间的差异是什么?</li><li>it’s just a question of whether the schema is explicit (enforced on write) or implicit (handled on read)?</li><li>关系型数据库的限制?什么导致了这些限制?如何打破这些限制?</li></ul><h2><span id="overview">Overview</span></h2><p>许多应用都由分层的 data-model 组成,上层屏蔽下层的复杂性,data-model 决定我们解决问题的思维模式.本节介绍 <code>relational model, document model, graph-based model</code> 3 种 data-model 和其对应的 query language。</p><p>Relational model 解决数据之间 <code>many-to-many</code> 关系的问题,但是无法适应所有应用场景,于是 <code>NoSQL datastore</code> 应运而生,主要分为 2 大类:</p><ol><li><p><code>Doucument database</code>: Document databases target use cases where data comes in <code>self-contained</code> documents and relationships between one document and another are rare.</p></li><li><p><code>Graph databases</code>: Graph databases go in the opposite direction, targeting use cases where anything is potentially related to everything.</p></li></ol><p>适应于一个 data-model 的数据也可以用其他的 data-model 来组织,比如: graph data can be represented in a relational database。用不合适的 data-model 来组织数据会使得数据变得难以使用, That’s why we have different systems for different purposes, not a single one-size-fits-all solution.</p><p>定义数据存储格式 -&gt; 在其上定义查询语言.</p><h2><span id="relational-model-versus-document-model">Relational Model Versus Document Model</span></h2><h3><span id="relational-model">Relational Model</span></h3><p>Relational Model 由 row(tuple) 组成 table(relation),主要的 use case 是 <code>transaction processing</code> 和 <code>batch processing</code>。其屏蔽了底层存储的实现细节,对外提供 sql 这种声明式的 query language.</p><p>Object-oriented 和 relational model 之间存在差异,需要 orm(mybatis 等), 但是也无法完全屏蔽这种差异.</p><p>A key insight of the relational model was this: you only need to build a query optimizer once, and then all applications that use the database can benefit from it</p><h3><span id="document-model">Document Model</span></h3><p>适用于数据之间 one-to-many 的关系,对 join 支持比较弱.</p><p>NoSql(Not Only SQL) 产生驱动因素: </p><ul><li>A need for greater scalability than relational databases can easily achieve, including very large datasets or very high write throughput</li><li>开源优势</li><li>Specialized query operations that are not well supported by the relational model</li><li>Frustration with the restrictiveness of relational schemas, and a desire for a more dynamic and expressive data model</li></ul><p><strong>Schema flexibility in the document model:</strong></p><ul><li>schema-on-read (the structure of the data is implicit, and only interpreted when the data is read),</li><li>schema-on-write(the traditional approach of relational databases, where the schema is explicit and the database ensures all written data conforms to it)</li></ul><p>schema-on-read approach is advantageous if the items in the collection don’t all have the same structure for some reason</p><h4><span id="many-to-one-and-many-to-many-relationships">Many-to-One and Many-to-Many Relationships</span></h4><p>Removing such duplication is the key idea behind normalization in databases.</p><ul><li>Relational model 通过外键来组织 one-to-many 的数据关系,通过 join 来查询数据,这种效率比较低。document model 对 one-to-many 支持良好, In document databases, joins are not needed for one-to-many tree structures, and support for joins is often weak.但是如果数据库不支持 join, 就需要自己在代码层面实现数据的 join 逻辑.</li></ul><p><a href="https://www.dlsweb.rmit.edu.au/Toolbox/knowmang/content/models/network_model.htm">The network model</a>: 树形结构,通过 link(类似指针而非外键), 支持多对多和多对一<br>The only way of accessing a record was to follow a path from a root record along these chains of links. This was called an access path.</p><p><img src="http://www.dlsweb.rmit.edu.au/Toolbox/knowmang/content/models/images/multiple_owner.gif" alt="img"></p><p><a href="https://www.dlsweb.rmit.edu.au/Toolbox/knowmang/content/models/relational_model.htm">The relational model</a>:</p><ul><li>数据被组织为表,没有嵌套的结构,可以在表上增删改查</li><li>查询路径由数据库的查询优化器自己选取,无需手动指定</li></ul><p><img src="https://www.dlsweb.rmit.edu.au/Toolbox/knowmang/content/models/images/relational_schema.gif" alt="img"></p><p>在 many to one 和 many to many 上 2 者没有本质差异,Relationl 使用外键,Document 使用 <code>document reference</code></p><p><strong>主要优势比较</strong>:</p><ul><li><p><code>Document model</code>: schema flexibility, better performance due to locality, for some applications it is closer to the data structures used by the application</p></li><li><p><code>Relational model</code>: better support joins, many-to-one and many-to-many</p></li></ul><h4><span id="data-locality-for-queryies">Data locality for queryies</span></h4><p>document 被连续存储,查询性能比较好; 如果被 split 为多个 table, 查询的开销更大<br>数据本地化的策略被大量使用,比如 column-family</p><h4><span id="convergence-of-document-and-relational-databases">Convergence of document and relational databases</span></h4><p>A hybrid of the relational and document models is a good route for databases to take in the future. 比如 <code>sql-on-elasticsearch</code>, <code>Phoenix</code></p><h2><span id="query-languages-for-data">Query languages for data</span></h2><h4><span id="sql">Sql</span></h4><p>Sql 基于 relatinoal algebra, 是声明式语言,它:</p><ol><li>sql 将查询逻辑和数据库实现解耦,使得 2 者之间可以独立的变化. it gives the database much more room for automatic optimizations.</li><li>sql 只是指明了查询模式,对执行顺序没有要求,所以可以方便的并行. because it specifies instructions that must be performed in a particular order. Declarative languages have a better chance of getting faster in parallel execution because they specify only the pattern of the results, not the algorithm that is used to determine the results</li></ol><h4><span id="mapreduce-querying">MapReduce Querying</span></h4><p>一些 NoSql DB 如 Manogo 使用 MR querying。MapReduce is neither a declarative query language nor a fully imperative query API, but somewhere in between.</p><p>The map and reduce functions are <code>somewhat restricted</code> in what they are allowed to do. They must be pure functions,</p><p>写 mr 程序比写 query 是要难的,A usability problem with MapReduce is that you have to write two carefully coordinated JavaScript functions, which is often harder than writing a single query</p><h2><span id="graph-like-data-models">Graph-Like Data Models</span></h2><p>适用于 many-to-many 模型,由 vertices 和 edges 组成, vertex 和 edge 不需要固定的 schema. graph 的 vertex 和 edge 不一定需要都是同一类,不同的 vertex 和 edge 之间可能会有各种个样的关系, 而且要在这些 vertex 和 edge 上进行各种关联查询. 如果用 Relational model 来表示,会不直观,比如查询需要写大量的 join,不同的 vertex 需要存储到不同表,且有严格的 schema 限制.</p><p><strong>构建灵活,利于演进:</strong></p><ul><li><p>Graphs are not limited to such homogeneous data: an equally powerful use of graphs is to provide a consistent way of storing completely different types of objects in a single datastore</p></li><li><p>Graphs are good for evolvability: as you add features to your application, a graph can easily be extended to accommodate changes in your application’s data structures.</p></li></ul><p><img src="https://s3.amazonaws.com/dev.assets.neo4j.com/wp-content/uploads/graph-database-connected-data-diaspora.png" alt="img"></p><h4><span id="property-graph-model">property graph model</span></h4><p>those features vive graphs a great deal of flexibility for data modeling</p><ol><li>没有 schema 限制类型</li><li>可以有效的查询一个顶点的出边和入边</li><li>可以存储额外的信息来描述边</li></ol><p>In the property graph model, each vertex consists of:</p><ul><li>A unique identifier</li><li>A set of outgoing edges</li><li>A set of incoming edges</li><li>A collection of properties (key-value pairs)</li></ul><p>Each edge consists of:</p><ul><li>A unique identifier</li><li>The vertex at which the edge starts (the tail vertex)</li></ul><h4><span id="the-cypher-query-language">The Cypher Query Language</span></h4><p>Cypher is a declarative query language for property graphs, created for the Neo4j graph database </p><p>如果用关系型 model 来表示图,用 sql 来进行图上的操作, sql 会异常复杂</p><h4><span id="triple-store-model">Triple-store model</span></h4><p>The triple-store model is mostly equivalent to the property graph model, using different words to describe the same ideas</p><p>In a triple-store, all information is stored in the form of very simple three-part state‐ments: <code>(subject, predicate, object)</code>.</p><p>but fortunately you can use semicolons to say multiple things about the same subject. This makes the Turtle format quite nice and readable:</p><h5><span id="the-semantic-web"></span></h5><p>RDF is designed for internet-wide data exchange,The Resource Description Framework (RDF) was intended as a mechanism for different web‐sites to publish data in a consistent format, allowing data from different websites to be automatically combined into a web of data—a kind of internet-wide “database of everything.”</p><p>RDF doesn’t distinguish between properties and edges but just uses predicates for both</p><p>Cypher’s pattern matching is borrowed from <code>SPARQL</code>.</p><h4><span id="graph-databases-compared-to-the-network-model">Graph Databases Compared to the Network Model</span></h4><ol><li>Network 规定了 link 的类型,类似 <code>java: Type link</code>, 而 graph vertex 可以和任意 vertex 建立联系,类似 <code>java: T link</code>,This gives much greater flexibility for applications to adapt to changing requirements.</li><li>在 network 中必须沿着 access path 进行数据查找. graph 中 you can refer directly to any vertex by its unique ID, or you can use an index to find vertices with a particular value</li><li>Network 中 the children of a record were an ordered set, so the database had to maintain that ordering, Graph 中 . In a graph database, vertices and edges are not ordered (you can only sort the results when making a query).</li><li>Network 中  all queries were imperative, Graph 支持 high-level, declarative query languages such as Cypher or SPARQL</li></ol><h4><span id="the-foundation-datalog">The Foundation: Datalog</span></h4><p>古老的 language, it provides the foundation that later query languages build upon. Cascalog 是其一种实现,用来查询 hadoop 上的数据集.</p><p>Dtalog 定义 data model 为: predicate(subject, object)</p><p>Cypher and SPARQL jump in right away with SELECT, but Datalog takes a small step at a time.But it’s a very powerful approach, because rules can be combined and reused in different queries. It’s less convenient for simple one-off queries, but it can cope better if your data is complex.</p><h2><span id="summary">Summary</span></h2><p>每种 model 适应于不同的场景,趋势是不同的 model 之间也在相互融合。</p><p>Relation model: </p><ul><li>适应于 many-to-many 和 many-to-one 的模式</li><li>良好的 join 支持, schema on write</li><li>Declarative query language: Sql, 解耦查询逻辑和数据库实现,使得查询优化器得以实现</li><li>对于 one-to-many 关系将数据 split 到多个 table 中,通过 join 查询降低数据的获取效率</li><li>用 join 来进行 graph 的查询难以理解且费时费力</li><li>和 OO 的设计之间存在差异,需要通过 ORM 来弥补</li></ul><p>Document model</p><ul><li>适应于 one-to-many, join 支持不够</li><li>灵活的 schema(schema on read)</li><li>data locality 带来的查询效率</li><li>Declarative query language: MR</li></ul><p>Graph model</p><ul><li>允许任意类型的 vertex 建立任意的 edge,灵活的 schema 非常便于应用扩展演进 </li><li>Declarative query language: Cypher, SPARQL</li><li>支持 graph 上的各种查询</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2&gt;&lt;span id&gt;?&lt;/span&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;有哪些 data model? 它们之间的区别和联系是什么? 各自解决了什么场景下的问题? 如何融合?&lt;/li&gt;
&lt;li&gt;每个 data model 对应的 query language 是什么? 有什么特点?</summary>
      
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="ddia" scheme="http://example.com/tags/ddia/"/>
    
  </entry>
  
  <entry>
    <title>Part 1: CHAPTER 1 Reliable, Scalable, and Maintainable Applications</title>
    <link href="http://example.com/2019/09/07/Part-1-CHAPTER-1-Reliable-Scalable-and-Maintainable-Applications/"/>
    <id>http://example.com/2019/09/07/Part-1-CHAPTER-1-Reliable-Scalable-and-Maintainable-Applications/</id>
    <published>2019-09-07T05:58:07.000Z</published>
    <updated>2022-11-25T07:02:35.753Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#">?</a></li><li><a href="#thinking-about-data-system">Thinking about data system</a></li><li><a href="#reliability%E5%8F%AF%E9%9D%A0%E7%94%A8%E6%80%A7">Reliability(可靠&#x2F;用性)</a><ul><li><a href="#hardware-faults">hardware faults</a></li><li><a href="#software-errors">software errors</a></li><li><a href="#human-errors">human errors</a></li></ul></li><li><a href="#scalability">Scalability</a><ul><li><a href="#describing-load-and-performance%E6%8F%8F%E8%BF%B0%E9%97%AE%E9%A2%98">describing Load and performance(描述问题)</a></li><li><a href="#approaches-for-coping-with-load%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98">approaches for coping with load(解决问题)</a></li></ul></li><li><a href="#maintainability">Maintainability</a></li></ul><!-- tocstop --><h2><span id>?</span></h2><ul><li>how we think of reliaility, scalability, maintainability?</li><li>how to achieve reliaility, scalability, maintainability?</li></ul><h2><span id="thinking-about-data-system">Thinking about data system</span></h2><ul><li><p>数据系统的特点是什么?<br>一方面,传统的数据系统都为了解决某个特定领域和场景的问题,而现在,这种界限在变得模糊,比如<a href="http://blog.rodeo.io/2016/01/24/kudu-as-a-more-flexible-kafka.html">将 kudu 用作消息队列</a>; 另一方面,为满足更多的需求,数据系统在变得复杂,需要组合多种组件来完成系统构建;</p></li><li><p>需要着重考虑和解决什么问题?<br>数据系统设计需要考虑人,技术等诸多因素,我们可以抽象出 3 个比较重要的关注点: Reliability, Scalability, Maintainability</p></li></ul><h2><span id="reliability可靠x2f用性">Reliability(可靠&#x2F;用性)</span></h2><p>Reliability 指的是当有 fault 发生,系统仍可以正常执行的能力,这称为 <code>fault-tolerant 或者 resilient</code>。fault(异常,会<code>导致failure</code>) 不同于 failure(失败,不可用), fault <code>无法完全避免</code>,所以需要构建容错机制,来 <code>cure fault,prevent failure</code>。Reliability 十分重要,对于 hardware faults, software errors and human errors 有不同的应对方法</p><h4><span id="hardware-faults">hardware faults</span></h4><p>它的特点如下,一般使用<code>硬件冗余</code>来解决问题,然而大规模的数据应用加剧了这个问题,需要引入软件容错</p><ul><li>MTTF &#x3D; 10~50 年,规模大了以后,硬件故障概率很高</li><li>随机发生和机器之间独立发生(random and independent)</li></ul><h4><span id="software-errors">software errors</span></h4><ul><li>特点: <ul><li>并非独立,难以预测</li><li>There is no quick solution to the problem of systematic faults in software</li></ul></li><li>solve: <ul><li>加强系统测试</li><li>进程隔离</li><li>重视监控,measuring,gurantee 等</li></ul></li></ul><h4><span id="human-errors">human errors</span></h4><ul><li>特点: 人的行为会导致很多错误,但是对人的行为管控严格的系统又缺乏灵活性,这需要做出权衡</li><li>solve: 权限管控&#x2F;灵活性(权衡), 快速恢复错误, 单元测试&#x2F;集成测试, 监控指标, 良好的管理实践与充分的培训</li></ul><h2><span id="scalability">Scalability</span></h2><p>Scalability means having strategies for keeping performance good, even when load increases.</p><h4><span id="describing-load-and-performance描述问题">describing Load and performance(描述问题)</span></h4><p>为了描述 scalability,我们需要描述系统的 load 和 performance,具体的 load 指标取决一个系统。描述 load 和 performance 之间的关系需要阐明 2 个问题:</p><ul><li>保持资源不变的情况下,提高 load, 对系统有何影响?</li><li>load 提高后,如果要保持 performance, 如何增加资源?</li></ul><p>对于 performance 的描述,平均值并不准确,这无法反映用户的实际体验,应该使用分布比率(percentile)来进行衡量,如 P50</p><h4><span id="approaches-for-coping-with-load解决问题">approaches for coping with load(解决问题)</span></h4><p>how do we maintain good performance even when our load parameters increase by some amount?</p><p>将有状态服务扩展到多个节点上是困难的,但是趋势如此。load 增长,需要改变系统架构: scale-up(vertical使用大型机) or scale-out(horizontal加机器) 或者 2 者进行结合,架构的扩展性设计基于应用的 load parameters, 但是也有一些通用的原则和设计,之后会进行讨论</p><h2><span id="maintainability">Maintainability</span></h2><p>软件的最大成本在于后学维护,可维护性系统的 3 个设计原则:</p><ul><li>Operability: 容易运维,这需要系统有良好的监控系统,完善的文档等来保证</li><li>Simplicity: 系统易于理解和使用,这需要系统设计具备良好的抽象性</li><li>Evolvability: 扩展性良好,基于前 2 点,可以使用 TDD 和 Refactoring 进行指导</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;!-- toc --&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#&quot;&gt;?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#thinking-about-data-system&quot;&gt;Thinking about data system&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#re</summary>
      
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="ddia" scheme="http://example.com/tags/ddia/"/>
    
  </entry>
  
</feed>
